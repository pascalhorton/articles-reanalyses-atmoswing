\documentclass[review]{elsarticle}
%\documentclass[5p]{elsarticle}

\usepackage{lineno,hyperref,gensymb,multirow}
\usepackage[textwidth=18cm]{geometry}
\modulolinenumbers[5]

\journal{Environmental Modelling \& Software}



% TODO: wider litterature review
% TODO: show scaling with multiple cores
% TODO: more technical stuff (e.g. classes + schemas)
% TODO: Raspberry Pi

% TODO: rewrite abstract
% TODO: add more references
% TODO: remove appendix ?
% TODO: add all reanalysis datasets
% TODO: add forecasts performances
% TODO: review: While the authors show a good command of the Analogue Technique and of its applications, it is not clear from the manuscript which predictors should be used for the forecast of alpine precipitations. The authors present two sets, that of Bontron (2004) and of Horton et al. (2012). An evaluation (or a summary, if already done elsewhere) of the relative merits of the two methods should be shown,
% TODO: relative merits of the metrics used (S1 or RMSE) are not explained
% TODO: article doesn't present any evaluation or validation of the precipitation fields/data or alerts provided by AtmoSwing
% TODO: the article is too general and descriptive and should detail the specifics of the present implementation of the Analogue Technique.
% TODO: Another point (though not a reason for rejection) is about the practical use for forecasters: as the authors rightly pointed out, it is impossible to apply analogue techniques directly on NWP forecasts of meteorological parameters, since the analogues are provided by other models, with different resolution. A coherent (I.e with the same model version and resolution) and long enough period of NWP forecasts can be hard to come by, especially for rare episodes. This may restrain the practical use of AtmoSwing for operational precipitation and flood forecasts. Maybe the authors could comment on that?


%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
%\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\begin{frontmatter}

\title{AtmoSwing: Analogue Technique Model for Statistical Weather forecastING and downscalING}


\author[unibe,unil,terranum]{Pascal Horton\corref{correspondingauthor}}
\cortext[correspondingauthor]{Corresponding author}
\ead{pascal.horton@giub.unibe.ch}


\address[unibe]{University of Bern, Oeschger Centre for Climate Change Research, Institute of Geography, Bern, Switzerland}
\address[unil]{University of Lausanne, Institute of Earth Sciences, Lausanne, Switzerland}
\address[terranum]{Terranum SARL, Bussigny, Switzerland}



\begin{abstract}
Analogue methods (AMs) allow predicting local meteorological variables of interest (predictand), such as the daily precipitation, on the basis of synoptic variables (predictors). They rely on the fact that similar meteorological influences are likely to result in similar local effects. This statistical relationship is thus based on archives of observed data, and used in order to operationally forecast the coming days, or to evaluate future conditions under a changing climate.

AtmoSwing is an open source software that implements different AM variants in a very flexible way, so that different variants can be handled dynamically, by parameterization through XML files. It is made of 3 tools: the Forecaster to perform operational forecasts, the Viewer to display the results, and the Optimizer to establish the relationship between the predictand and predictors. 

The Forecaster handles every required processing internally, such as predictors downloading and reading, grid interpolation, analogy sorting, without external scripts or file conversion. The processing of a forecast is extremely lightweight in terms of IT infrastructure; it can indeed run on almost any computer.

The Viewer displays the forecasts in an interactive GIS environment. It contains several layers of syntheses and details in order to provide a quick overview of the potential critical situations in the coming days, as well as the possibility for the user to go into the details of the forecasted predictand and criteria distributions. Several tips coming from the literature are provided in order to help interpreting the forecasts.

The Optimizer integrates the common semi-automatic sequential approach, as well as Monte--Carlo analyses, and a global optimization technique by means of Genetic Algorithms. 

\end{abstract}

\begin{keyword}
analogue method, precipitation, downscaling, forecasting
\end{keyword}

\end{frontmatter}

\linenumbers


\section{Introduction}

Approaches based on the concept of analogy is rather widespread in different domains of sciences or engineering. In hydrometeorology it consists in retrieving atmospheric situations from the past that can be considered similar to the situation at hand and therefore with consequences that may be expected similar. Consequences can be local variables of interest, such as the occurrence of fog, favourable conditions for avalanches, the wind intensity, or the precipitation amount. It relies on the idea expressed by \citet{Lorenz1956, Lorenz1969} that similar situations in terms of atmospheric circulation are likely to lead to similar local weather. The approach requires at least two concurrent archives: one describing the situation through different variables, called predictors, and another one providing the value of the local variable of interest, called predictand.

Usually, the predictand values could be derived by modeling the chain of processes linking the predictors to the predictand. The processes involved range from large scale dynamical states of the atmosphere down to very small scale microphysical processes, requiring models that are extremely complex, data-demanding, and time consuming. Conversely, given an appropriate set of predictors archives, enough situations analogous to a target one could be found so that reasonable values will be obtained for the predictand, at a reasonable coding and computing-time costs. This is particularly true for a predictand much required in hydrometeorological applications, namely the precipitation amount over a given domain and time duration. Incidentally, the forecast will be proposed as a statistical distribution based on the values taken by the predictand in the set of analogues selected, unless one considers only the single best analogue, which may not prove the most efficient \citep{Bontron2005}.

Analogue methods (AMs) are used in two different kind of approaches \citep{Rummukainen1997}: perfect prognosis, for which the statistical relationship is calibrated based on observed predictors, and model output statistics (MOS), for which the relationship is calibrated against the outputs of a specific climate or numerical weather prediction (NWP) model. It is often used to predict daily precipitation, either in an operational forecasting context \citep[e.g.][]{Guilbaud1997, Bontron2005, Hamill2006, Bliefernicht2010, Marty2012, Horton2012, Hamill2015, BenDaoud2016} or a climate downscaling context \citep[e.g.][]{Radanovics2013, Chardon2014, Dayon2015, Raynaud2016b}. Other predictands are also considered, such as precipitation radar images \citep{Panziera2011,Foresti2015a}, temperature \citep{Radinovic1975, Woodcock1980, Kruizinga1983, DelleMonache2013, Caillouet2016, Raynaud2016b}, wind \citep{Gordon1987, DelleMonache2013, DelleMonache2011, Vanvyve2015, Alessandrini2015, Junk2015, Junk2015c}, solar radiation or power production \citep{Alessandrini2015a, Bessa2015, Raynaud2016b}, snow avalanches \citep{Obled1980, Bolognesi1993}, and the trajectory of tropical cyclones \citep{Keenan1981, Sievers2000, Fraedrich2003}. \citet{Guilbaud1997} performed a literature review about the use of the AM in long-term forecasting and identified operational applications for monthly forecasts in many countries, including Canada \citep{Shabbar1986},  Hungary \citep{Toth1989}, the Netherlands \citep{Nap1981}, and England \citep{Murray1974}, as well as seasonal forecasts: \citet{Barnett1978}, \citet{Bergen1982} and \citet{Livezey1988}.

The use of the AMs for operational forecasting of daily precipitation originates in the work of \citet{Duband1970, Duband1974, Duband1981}. It was then designed for operational forecasting at EDF (Electricit\'{e} de France) in order to better manage water resources and flood risks. They have been used mainly by practitioners, notably hydropower companies \citep{Desaint2008a,BenDaoud2009,Obled2014} or flood forecasting services in France and Switzerland \citep{Marty2010,GarciaHernandez2009b,Horton2012}. Comparing the results from AMs to an ensemble forecast, \citet{Marty2010} found AMs to be better than the considered ensemble, particularly for strong precipitation. AMs should however not be considered as a substitute for NWP models, but as a complement in order to get a fast and partly independent forecast that is known to be accurate several days in advance. They therefore enrich the analysis of a potential critical situation for flood forecasting, for example, and are very interesting in early warning.

The present work does not present a new method, but a software, named AtmoSwing, implementing AMs in a versatile and efficient way. Versatile, as it allows building AM structures in a dynamic way, through the use of XML files, and because the code is written with an object-oriented architecture. Efficient, as it is written in C++ and allows parallel computing. AtmoSwing is made up of different modules targeted either for operational forecasting (the Forecaster and the Viewer) or for climate impact studies (the Downscaler). Additionally it provides a module to calibrate the different parameters of the method, namely the Optimizer. AtmoSwing is continuously evolving and has been used in \citet{Horton2012, Horton2017a, Horton2017b, Horton2018a} and \citet{Horton2018b}.

Some existing AMs designed for daily precipitation will first be described along with the required data (Sect. \ref{sec:data_methods}) and the software will then be presented (Sect. \ref{sec:atmoswing}) and its modules detailed: the Forecaster (Sect. \ref{sec:forecaster}), the Viewer (Sect. \ref{sec:viewer}), the Downscaler (Sect. \ref{sec:downscaler}), and the Optimizer (Sect. \ref{sec:optimizer}). The conclusion (Sect. \ref{sec:conclusions}) provides some additional perspectives for future developments of AtmoSwing. 


\section{Data and methods}
\label{sec:data_methods}


\subsection{Required data}
\label{sec:data}

AMs generally require three datasets: one of the historical predictand values, one of the historical predictor values for the same period and another one of the predictors describing the target situation.

The predictand is often daily time series. It can have a higher temporal resolution, such as 6-houry, but not higher than the time step of the predictors. The most used predictand is the daily precipitation, usually averaged over subregions in order to smooth local effects \citep{Obled2002, Marty2012}. These time series are frequently normalized by the precipitation value for a return period of 10~years \citep{Djerboua2001}. This normalization allows for an easier comparison between subregions subject to different precipitation regimes, and thus to better identify the most important contributions.

In the early days of the method, the predictors were based on radiosounding data. Nowadays, the predictors archive is often a global atmospheric reanalysis dataset, which provides gridded large-scale variables at any location in the world. Reanalyses are produced using a single version of a data assimilation system coupled with a forecast model constrained to follow observations over a long period. They provide multivariate outputs that are physically consistent, which contain information in locations where few or no observations are available, also for variables that are not directly observed \citep{Gelaro2017}. Even though reanalyses are considered as very accurate in a data-rich region such as Europe, they can have a non-negligible impact on the skill of the prediction that can be even higher than the choice of the predictor variables \cite{Dayon2015, Horton2018b}. AtmoSwing can read the native files of ten reanalyses (Table \ref{table:datasets}), and others can be easily added thanks to the encapsulation of the dataset characteristics in the objects. Users can find recommendations for the selection of a reanalysis in \cite{Horton2018b}. Other predictor archives can also be used, such as Sea Surface Temperature \citep[SST, ][]{Reynolds2007}. \citet{Bontron2004} proposed that the minimum length of the archive should be 30 years to predict usual situations, and 40 years or more for intense events.

The predictors dataset describing the target situation varies according to the application of the AM. For operational forecasting (Sect. \ref{sec:forecaster}) they are outputs of NWP models, such as GFS \citep[Global Forecast System,][]{Kanamitsu1991,Kanamitsu1989}, which is operated by NCEP and NOAA. For climate impact studies (Sect. \ref{sec:downscaler}), they are outputs of general circulation models (GCMs) or regional climate models (RCMs), such as the Coupled Model Intercomparison Project Phase 5 \citep[CMIP5,][]{Taylor2012} and EURO-CORDEX \citep{Jacob2014}.


\subsection{Analogue methods for daily precipitation}
\label{sec:method}

AtmoSwing does not rely on a single variant of the AM, but can implement different variants. A non-exhaustive selection will be presented hereafter, focusing on the prediction of daily precipitation. Some of these are more specific for a certain region and may not be relevant for others, and some perform better depending on the lead time.


\subsubsection{Characteristics of the AM}

\textit{Definition of the analogy} -- The AM is based on the principle that two similar synoptic situations may produce similar local effects \citep{Lorenz1956}. The perfect analogy does not exist, but sufficiently similar situations leading to similar effects can be identified. Thus, two states of the atmosphere that are alike are called analogues \citep{Lorenz1969}. To be relevant, this analogy must be selected by optimizing the following elements:

\begin{itemize}		
	\item The meteorological variables (predictors) must contain synoptic scale information having a direct or indirect dependency with the target predictand.
	\item The pressure level, or height, at which the predictor is selected.
	\item The spatial window is the domain on which predictors are compared. The ideal size of this area is that which maximizes the useful information and minimizes noise.
	\item The temporal window is the hour(s) of the day at which the predictors are considered.
	\item The analogy criterion, needed to compare the variables on the chosen spatial and temporal windows, is a distance measure, used to rank observed situations according to their degree of similarity with the target situation.
	\item Eventual weights between the predictors \cite[e.g.,][]{Horton2017b, Junk2015}.
	\item The optimal number of analogue situations $N_{i}$ for the level $i$ which is the best compromise in order to take into account local variability and maximize useful synoptic information.
\end{itemize}

\textit{Seasonal preselection} -- \citet{Lorenz1969} restricted the search of analogue situations to the same period of the year to be comparable in terms of distribution of solar energy. This preselection is now often implemented as a moving selection of $\pm$60~days around the target date, for every year of the archive (Table \ref{table:methods}). Alternatively, the candidate dates can be selected based on similar air temperature at the nearest grid point \citep[Table \ref{table:methods}][]{BenDaoud2016}.

\textit{Analogy of atmospheric circulation} -- A conditioning by variables describing the atmospheric circulation is present in a vast majority of AMs. The geopotential field (Z) is often used as predictor since \citet{Lorenz1969}, who based the analogy on the levels 200, 500, and 850~hPa. Several pressure levels were later assessed by means of various criteria for the analogy on the geopotential field \citep{Duband1970, Duband1974, Duband1981, Guilbaud1997}. It was found to be important to compute the analogy on multiple pressure levels and different temporal windows (time of observation) instead of a unique selection \citep{Guilbaud1998, Obled2002}. \citet{Bontron2004} showed that the choice of the temporal window has a higher importance than the choice of the atmospheric level for the performance of the AM for daily precipitations. He concluded that the coupled geopotential heights at 1000~hPa (Z1000) at 12~h and 500~hPa (Z500) at 24~h provided the best performance \citep[for a subset of the NCEP/NCAR Reanalysis I;][]{Kalnay1996, Kistler2001} for the studied regions in France (Table \ref{table:methods}). The analogy on the atmospheric circulation proposed by \citet{Bontron2004} is still, at the time of writing, used operationally. \citet{Marty2010} tested other temporal windows for intraday application on the basis of a more comprehensive reanalysis dataset and proposed to change the hours of observation to 06~h and 18~h. \citet{Horton2018a} showed that a selection of four combinations of pressure levels and temporal windows for the geopotential height instead of two improve the prediction skill (PC-4Z, Table \ref{table:methods}). The pressure levels and temporal windows were automatically selected by genetic algorithms for the upper Rhone catchment in Switzerland.

\textit{Additional levels of analogy} -- Additional levels of analogy are subsequent steps that subsample a lower number of analogue situations from the antecedent level of analogy, based on other variables. A second level of analogy was first introduced by \citet{Mandon1985}, \citet{Vallee1986}, and \citet{Gibergans-Baguena2007}, based on wind, moisture variables, stability indexes, or temperature. After a systematic assessment, \citet{Bontron2004} pointed out that a moisture index (MI) made of the product of relative humidity at 850~hPa (RH850) and total precipitable water (TPW) gave the best performance (Table \ref{table:methods}). This index does not represent an actual physical quantity, but expresses the water content of the air column and its proximity to saturation. \citet{Marty2010} selected the MI at 925~hPa instead of 850~hPa, and also considered the moisture flux (MF) at 700 or 925~hPa (Table \ref{table:methods}). MF is the product of MI with the wind intensity. \citet{Horton2018a} found MI at 600 and 700~hPa more skillful than MF after the circulation analogy on the 4 atmospheric levels (Table \ref{table:methods}). \citet{BenDaoud2016} also reconsidered the parameters of MI and ended up with both 925~hPa and 700~hPa levels (Table \ref{table:methods}). Subsequently, they added an additional level of analogy between the circulation and the moisture analogy (Table \ref{table:methods}) based on vertical velocity at 850~hPa (W850). This AM, named "SANDHY" for Stepwise Analogue Downscaling method for Hydrology \citep{BenDaoud2016, Caillouet2016}, was primarily developed for large and relatively flat/lowland catchments in France (Sa\^{o}ne, Seine).

\textit{Analogy criteria} -- In early applications of AMs, the geopotential height was condensed by a principal component analysis (PCA) and the selection of analogue situations was done according to an Euclidean distance in the space of the PCA, eventually combined with a correlation criterion in order to remove days close in distance but too dissimilar in pattern. \citet{Guilbaud1997} stopped using PCA to work directly with the raw data interpolated on grids, which resulted in an improvement. In the case of variables describing the atmospheric circulation, the Teweles--Wobus (S1) criterion \citep[Eq. (\ref{eq:S1}), ][]{Teweles1954, Drosdowsky2003} was identified as the most suited criteria by different studies \citep{Wilson1980, Woodcock1980, Guilbaud1998, Bontron2004}. S1 allows for a comparison of the gradients, and thus an analogy of the atmospheric circulation instead of an Euclidean distance. The S1 criterion is usually not relevant for other predictors that the atmospheric circulation. For other predictors, classic criteria representing absolute distances are used: Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE), the latest being most often used.

\begin{equation}
\label{eq:S1}
S1=100 \frac {\displaystyle \sum_{i} \vert \Delta\hat{z}_{i} - \Delta z_{i} \vert}
{\displaystyle \sum_{i} max\left\lbrace \vert \Delta\hat{z}_{i} \vert , \vert \Delta z_{i} \vert \right\rbrace }
\end{equation}
where $\Delta \hat{z}_{i}$ is the forecast geopotential height difference between the \textit{i}th pair of adjacent points from the grid of the target situation, and $\Delta z_{i}$ is the corresponding observed geopotential height difference in the candidate situation. The differences are processed separately in both directions. The smaller the S1 values, the more similar the pressure fields.

\textit{Other parameters} -- The predictors are compared on a defined spatial window, which must be optimal to maximize the useful information and minimize noise. The spatial window is usually considered unique for all predictors of a level of analogy. With the use of genetic algorithms, \citet{Horton2018a} introduced different spatial windows between the pressure levels, which increased the performance. Aditionally, a weighting between the predictors was also successfully added instead of a simple equal-weights averaging. The number of analogues to select at each level of analogy should be optimized. It depends on the predictor dataset, the size of the spatial window and the length of the archive \citet{Ruosteenoja1988, Vandendool1994}.

\textit{Probabilistic forecast} -- After the last level of analogy, the observed predictand of interest (for example daily precipitation amount) of the $N_{i}$ resulting dates provide the empirical conditional distribution considered as the probabilistic forecast for the target day. The empirical frequencies are processed for every value of the predictand, after classification, based on the Gringorten parameters \cite[for a Gumbel or exponential law; see][]{Gringorten1963} and a probabilistic model can eventually be fitted \citep[e.g. Gamma function,][]{Obled2002}. The forcast is finally often synthetized by the percentiles 20, 60 and 90~\% \citep{Guilbaud1997, Guilbaud1998}.

\textit{Use in operational forecasting} -- In one of the very first use in operational forecasting, the forecast was performed only on the basis of radiosonde observations and was temporally extrapolated to the two following days. However, because of the chaotic nature of the atmosphere, two analogue situations quickly diverge over time \citep{Lorenz1969}. Thus, the AM has strong limitations regarding the temporal extrapolation in operational forecasting \citep{Bontron2004}. Numerical models being more capable of simulating the dynamic evolution of the atmosphere, the temporal extrapolation of the synoptic variables is left to them. The search for analogy aims thus at connecting the forecasted synoptic situation with a local predictand (temperature, precipitation, etc), which is more difficult to simulate by numerical models. When using AMs in operational forecasting, one has to be aware that some variables, such as moisture or vertical velocity, might not be accurately predicted after a lead time of a couple of days due to higher uncertainties. Predictors describing the atmospheric circulation are generally considered more reliable.


\subsubsection{Regional characteristics}

The optimal predictors vary from one region to another, along with the leading atmospheric processes. One will thus never get a unique version of the AM valid for any place on earth, but the method needs to be adapted to the local conditions, available data, and to the size of the catchment of interest. Thus, there will always be local adaptations to be made for use in a new region. Even for two locations that are close to each other but subject to different critical atmospheric conditions, the selection of the best predictors can vary. This is illustrated in Fig. \ref{figure:variable_exploration} for two subregions of the Rh\^{o}ne catchment in Switzerland. For both regions, all variables of NR-1 were assessed by optimizing the spatial window and the number of analogues for each one of them using the sequential calibration tool implemented in AtmoSwing (Sect. \ref{sec:vars-explo}). The main similarities in the selection of the best predictor from the NCEP/NCAR reanalysis I at both locations are: (1) the variables describing the atmospheric circulation (pressure fields or geopotential heights) perform best, and (2) these are better when compared by means of the S1 criteria (asterisk in Fig. \ref{figure:variable_exploration}) instead of the RMSE. The main difference is that the pressure fields explain better the precipitation when they are considered close to the ground for the Chablais region, but at higher altitude for the South-east crests. This is driven by the elevation of the stations and by the main atmospheric influences related to precipitation events at these locations. 

The choice of the best predictors is likely to vary from one reanalysis dataset to another. This comprehensive comparison was not repeated with other datasets, as a selection of the best predictors by genetic algorithms would be less cumbersome (Sect. \ref{sec:global-optimization}).


\subsubsection{Method nomenclature}

Variants of the AMs are numerous and it is not always easy to reference them in a short and descriptive way. In AtmoSwing, a basic nomenclature is used (Fig. \ref{figure:nomenclature}) in order to express the structure into a simple identifier. This one cannot describe all the parameters of the AM, but quickly illustrate the structure of the implementation. This is particularly useful when working with a global optimization method, where nothing is fixed but the very structure of the AM. This nomenclature has been used in \citet{Horton2017a, Horton2017b, Horton2018a} and \citet{Horton2018b}.

The naming contains different blocs (separated by an hyphen) for the various levels of analogy. It starts with the specification of the preselection (P; can be omitted when comparing AMs with the same preselection approaches), which can be nowadays of 2 types:
\begin{itemize}
	\item PC: calendar period ($\pm 60$ days around the target date)
	\item PT: based on air temperature \citep{BenDaoud2010}
\end{itemize}

Then, the following levels of analogy are listed, which may start with an optional A (for analogy). For every level of analogy, the number of variables used (combination of atmospheric levels and time of observation) is first provided, and then the short name of the variable is given (according eg to ECMWF conventions; in upper case), for example:
\begin{itemize}
	\item Z : geopotential (circulation)
	\item TPW : total precipitable water
	\item RH : relative humidity
	\item V : wind velocity
	\item W : vertical velocity
	\item MI : moisture index (TPW * RH)
	\item MF : moisture flux (V * TPW * RH)
\end{itemize}

In order to keep the identifier simple, no value of atmospheric level neither time of observation is specified. Moreover, the analogy criterion is not specified and is supposed to be S1 for Z and RMSE for the other variables. If anything changes from these conventions, it can be noted as a flag. The flag (lower case) can also give other information, such as the optimization method:
\begin{itemize}
	\item sc : sequential calibration (can be omitted as considered as default, see Sect. \ref{sec:atmoswing-calibration})
	\item go (or just ''o'') : global optimization (by means of genetic algorithms for example)
\end{itemize}

This nomenclature can be adapted to specific needs, or simplified for a better readability (eg. by removing the specification of the preselection). Examples can be found in Table \ref{table:methods}.


\section{AtmoSwing}
\label{sec:atmoswing}

AtmoSwing is made of 4 main modules that are standalone, but do share a common code basis: the Forecaster for operational forecasting, the Viewer, to display the forecast in a GIS environment, the Downscaler for climate applications, and the Optimizer, to calibrate/optimize the statistical relationship defining the analogy for a given predictand time series. Separating the Forecaster and the Viewer allows to automate the forecast on a server and to quickly display the results locally. The Forecaster, the Downscaler and the Optimiser can be either used with a graphical user interface or with a command-line interface.


\subsection{Technical aspects}

The code is written in object oriented C++ and relies on the wxWidgets \citep{Smart2006} library to provide a cross-platform native experience to users. CMake is used to build AtmoSwing on MS Windows, Linux / Unix, or Mac (macOS). The source code in under version control (Git), and is open source (on Github, www.atmoswing.org). Developments have been partly made with a test driven development (TDD) approach. A continuous integration has been setuped so that a collection of more than 500 tests are evaluated every time new code is pushed to ther server, to prevent regressions. Every analogy criterion, prediction score, searching and sorting functions, data manipulation, and so on, is tested. Some tests specific to the AM rely on the results of another analogue sorting software developed at the Universit\'{e} Grenoble Alpes. They ensure that the results of AtmoSwing are exactly equivalent to their model, given the same parameters and data. 

Although processing an analogue prediction for a given target date is fast, hindcasts over periods of several decades must be performed for calibration, which may become very time consuming. Thus, great effort has been made to reduce the processing time to a minimum by means of profiling tools. First, all identified redundancies in processing were removed. Then, when looking for a certain date or data, it is first searched in the region where it is likely to be found instead of exploring an entire array. Similar data are not loaded twice, but shared pointers are used. Many other improvements allowed saving more time, for example the use of the quicksort method \citep{Hoare1962a} to sort the date vectors according to the analogy criterion. Different implementation variants were tested in order to select the most efficient one: for example, when storing analogue dates according to their criterion value, it is faster to insert them in a fixed-size array rather than storing them all and sorting the array subsequently. When using the S1 criteria, the gradients are preprocessed on the predictor data, so they are only processed once. AtmoSwing also uses the linear algebra library Eigen 3 \citep{Guennebaud2010} for calculations on vectors and matrices, which resulted in time saving. Multi-threading is also implemented so that the search for analogue situations in the archive is distributed among the available threads.

A user interface allows the creation of the predictand database. Its generation consists in extracting the time series from text files to save a database in the NetCDF format. During the process, Gumbel adjustments are automatically calculated for precipitation data to determine the values corresponding to different return periods. The time series are normalized by a selected return period (default 10~years) and their square root can be processed. The final database file contains both the raw and the normalized series, as well as characteristics of the gauging stations and some metadata.


\subsection{Modular approach and implementation}

AtmoSwing's great strength is that it is designed to process the analogue method in a modular fashion. The structure of the AM (number of analogy levels, number of predictors) is built dynamically (Fig. \ref{figure:flowchart_modules_atmoswing}), and nothing is fixed a priori. The software then performs successively as many analogy levels as the user specified, with all the predictors he wants. Each level of analogy result in an object containing target dates, analogue dates, values of the analogy criteria, values of the predictand (at the final stage), and other data. This object can be saved as a NetCDF file and/or can be injected into a new analogy level. The whole structure of the AM is defined by the user through an XML file. Even the time step of the method (6 or 24~hours for example) is a dynamic parameter.

Each implementation of the AM (see Sect. \ref{sec:method}) may enter this scheme, even if it consists of preprocessed variables (e.g. moisture index). Various preprocessing functions are implemented, as the calculation of the moisture index or flux, multiplication operations or calculation of the gradients. The user can specify the preprocessing method and the predictors to use, dynamically, in the XML file.

This modular approach is implemented through object-oriented programming, specifically thanks to polymorphism. This allows for example to process a predictor object as a single inferface to entities representing any reanalysis dataset. Similarly, the criterion can be of different types, as well as the score for calibrating. Figure \ref{figure:code_diagram} illustrates in a simplified way the main classes or objects involved in the core of the analogue method processing in AtmoSwing. The different types of objects that are instantiated are defined in the XML parameters file. Thus, there is a single implementation of the analogue method capable of interacting with different object types in various context (calibration, forecasting, downscaling).


\subsection{AtmoSwing Forecaster}
\label{sec:forecaster}

The Forecaster module allows to process operational forecasts. The software can be compiled with a graphical user interface (GUI, Fig. \ref{figure:atmoswing-forecaster-gui}), or without it to be used on a headless server through a command line interface (CLI). Processing a forecast requires very low computing capabilities and can be done on a low-end computer. It sucessfully runs on a Raspberry Pi 3 (Model B).

The software first downloads the predictor describing the target situation, such as 1\degree\ GFS outputs \citep[Global Forecast System,][see Sect. \ref{sec:data}]{Kanamitsu1991,Kanamitsu1989}. It then interpolates linearly the gridded data to match the resolution of the archive. The analogues dates are next extracted according to the selected AM variant, and the predictand data are associated with the corresponding dates. The results are finally saved in auto-describing NetCDF files. If requested, a synthetic XML file is generated for an easier integration on a web platform for example. Every step of the forecast, from the predictor downloading (when possible) to the final results, is done in the software (and controlled through configuration), without use of external scripts (e.g. for data conversion).

Both the GUI and the CLI allow to make a forecast based on the most recent NWP outputs, or for a given date or period. When there is no new predictor data available, the forecast is not processed and no computing resources are lost. The recommended use is thus to set up a cron task on a Linux server to trigger the forecast every 30 minutes. When using GFS outputs, this would provide four forecasts a day with a reduced delay between GFS outputs availability and the analogue forecast.

Before being used in operational forecasting, the AMs were calibrated in a perfect prognosis framework, usually by using a reanalysis dataset (Sect. \ref{sec:atmoswing-calibration}). However, this does not take into account the uncertainty related to the forecast of the target situation by Numerical Weather Prediction models. One might be willing to take into account this uncertainty, which is increasing with the lead time. A solution consists in increasing the number of analogue situations with the lead time, which should be optimized for every lead time on a forecast archive or a reforecast dataset \citep{Thevenot2004}. This technique is available in AtmoSwing, as the number of analogues can be specified for every lead time.

A meteorological variable that was proven to be a good predictor in the perfect prognosis framework may eventually be poorly predicted by the selected NWP beyond a certain lead time. It should then be dropped after the lead time in question (see Sect. \ref{sec:interpreting}). For example, when using moisture variables for the second level of analogy, \citet{Thevenot2004} showed that beyond a lead time of three days the AM with two levels did not perform better that the one with a single level of analogy. To assess and address these operational aspects, the best option is to collect a dataset of reforecast from the selected NWP model. Then, distinct variants of AMs can be assessed on different lead times. 


\subsection{AtmoSwing Viewer}
\label{sec:viewer}

AtmoSwing Viewer allows displaying the files produced by the Forecaster in an interactive GIS environment (Fig. \ref{figure:atmoswing-viewer-gui}). It provides several levels of synthesis of the forecasts. It first shows an overview of possible alerts by means of color codes on the lead time switcher (upper right in the GUI, see Fig. \ref{figure:atmoswing-viewer-gui}) that represent the worst case scenarios, or in the alarms panel (on the left side of the GUI). The alarms panel offers a synthesis of the highest forecasted values for the different AMs and the different lead times. By default, the colors are expressed relatively to the 10~year return period, for the $90^{th}$ percentile (which can be changed in the preferences). This highest level of synthesis allows to quickly identify potential critical situations in the days ahead.

Then, the user can explore the forecasts in more details, starting from the provided map (Fig. \ref{figure:atmoswing-viewer-gui}). The map displays the forecast of the selected AM variant (selected in the upper left panel) and the selected lead time (upper right). During the forecast, one AM might have parameters that differ by subregions, such as the number of analogues or the spatial windows. The Viewer automatically gathers the similar AM types and provides a composite view of the optimal forecasts per subregion. The user can however choose to display the results associated to a single parameter set for the whole region (by opening the tree view and selecting a child element), which provides a homogeneous set of analogue dates. A display of all lead times on a single map is made possible by means of a symbolic representation on a circular band with a box for every lead time (Fig. \ref{figure:atmoswing-viewer-snail}). The number of boxes is adjusted to the number of lead times. This representation offers a global spatiotemporal visualization for a chosen AM.

Color scales in the map can be adjusted by choosing (on the left part of the GUI) the predictand reference (raw value or ratio to different return periods) and the quantile of the distribution. Using a ratio to a certain return period eases the interpretation of the expected precipitation as reference volumes can drastically differ from one location to another, particularily in mountainous regions. All information relative to a rain gauge station (or catchment), such as its location, its name, or the values of different return periods, are stored in the forecast files to be displayable for end users who do not have the predictand database.

By clicking on a station on the map (or by selection in a dropdown list on the left), a new window appears with a plot of the forecasted time series (Fig. \ref{figure:atmoswing-viewer-timeseries}). By default, the plot contains the usual three considered percentiles (90$^{th}$, 60$^{th}$, and 20$^{th}$), along with the 10 best analogues with a color code from yellow (tenth) to red (first). The 10 year return period value is also displayed to set the forecast in perspective. The user can choose to hide any data or to display supplementary information (all analogues, all 10$^{th}$ percentiles, or all return periods) in the left panel. Traces of previous forecasts are also automatically loaded and displayed to provide information on the consistency of the forecasts. 

The user can then go into further details and display the predictand cumulative distribution for a given lead time (Fig. \ref{figure:atmoswing-viewer-distribution}). This can inform if there is a shift between the distribution of all analogues versus the 10 best. Such a shift warns of a risk of under/overestimation when considering the full distribution, particularily for high precipitation amount. Indeed, the number of extreme precipitation events in the archive is limited and they are thus likely to be underrepresented in the selected analog dates. Different authors showed that if the 60$^{th}$ percentile is best to forecast the occurrence and the amount of precipitation for common situations, the 90$^{th}$ percentile is a better indicator for strong to extreme events \citep{Djerboua2001, Bontron2004, Marty2010}. It is therefore necessary to pay attention when the 90$^{th}$ percentile reaches high values, as it may be indicative of possible extreme precipitations due the presence of several analogue dates with high precipitation amounts in the distribution \citep{Djerboua2001}.

The distribution of the analogy criteria (not shown) can also be displayed to identify eventual discontinuities in the criteria values. Finally, one can display a grid containing the analogue dates with the corresponding predictand and criteria values in an interactive spreadsheet (not shown).

AtmoSwing Viewer relies on workspaces, defined in XML files, to specify the path to the forecast directories and the GIS layers. It is thus easy to switch from a forecast for a region to another. Many GIS formats are supported thanks to GDAL \cite[Geospatial Data Abstraction Library,][]{GDAL2014}. One can has as many layers as wanted, and can control their display properties (color, transparency).


\subsection{AtmoSwing Downscaler}
\label{sec:downscaler}

The Downscaler module is the last addition to AtmoSwing. Its purpose is to downscale either climate model outputs for climate impact studies or reanalyses for climate reconstruction of the past. 

The Downscaler is able to read outputs of general circulation models (GCMs) or regional climate models (RCMs), such as the Coupled Model Intercomparison Project Phase 5 \citep[CMIP5,][]{Taylor2012} and EURO-CORDEX \citep{Jacob2014}, and can be extended to other datasets. CMIP5 and EURO-CORDEX are distributed in the NetCDF format, but present a great variety of time steps, temporal references, spatial resolution, and file structures. A complete redesign of the management of predictor data was necessary to provide the flexibility required to account for this variety. The Downscaler is thus able to parse these datasets' original files by exploiting the self-descriptive capacity of NetCDF files.

The use of AMs in the context of future climate is rather new. All AMs cannot be used for this purpose, as some predictors might not capture the climate change signal well, and the preservation of the relationship between predictors and predictands must prevail. However, some authors demonstrated the transferability of some AMs for a future climate \citep{Dayon2015, Dayon2018, Raynaud2016, Turco2017}. The transferability of an AM must be assessed before it is used in such context. 

AMs have also been used to perform climate reconstruction of the past \citep{Caillouet2016, Caillouet2017, Bonnet2017}. Such applications allow for example for hydrological modelling of flood events in periods where no meteorological data was available, or analysis of past severe droughts.


\subsection{AtmoSwing Optimizer}
\label{sec:optimizer}

AtmoSwing Optimizer is a single tool that integrates different optimization methods, presented in Sect. \ref{sec:atmoswing-calibration} to \ref{sec:global-optimization}. Optimization is essentially performed in the calibration framework (Sect. \ref{sec:calibration-framework}), where one tries to maximize (Sect. \ref{sec:scores}) the information that can be extracted from the available predictors and predictand archives.


\subsubsection{Calibration framework}
\label{sec:calibration-framework}

The calibration of the AM is usually carried out in a perfect prognosis \citep{Klein1959} framework \citep{Bontron2004, BenDaoud2010}. Perfect prognosis uses observed or reanalyzed data to calibrate the relationship between predictors and predictands, as opposed to the MOS approach that establishes the relationship on model outputs. As a result, perfect prognosis will provide relationships that are as close as possible to the natural links between predictors and predictands. However, no model is perfect and even reanalysis data may contain bias that cannot be ignored \citep{Dayon2015, Horton2018b}. Thus, the considered predictors should be as robust as possible, i. e. they should depend as little as possible on the model, but rather on observations. With MOS approaches, reforecasts can be used to establish the relationship between predictors and predictands, provided they are long enough. However, the calibration procedure must be performed again every time a new version is available in order to reduce the bias \citep{Wilson2002}.

The statistical relationship is established on a calibration period that is as long as possible. A prediction is performed for every day of this period. A certain numer of days around the target date are excluded to consider only independent candidates days. An independent validation period is always considered and its data is never used as target neither candidate. Validating the parameters of AMs is very important to avoid over-parametrization and to ensure that the statistical relationship is valid for another period. In order to account for climate change and the evolution of the measuring techniques, it is recommended to use a noncontinuous period for validation, distributed over the whole archive \citep{BenDaoud2010, Horton2018b}. AtmoSwing's users can thus specify a list of the years to set apart for the validation, which are removed from possible candidate situations. At the end of the optimization, the validation score is processed automatically.


\subsubsection{Implemented performance scores}
\label{sec:scores}

Multiple scores are implemented in AtmoSwing Optimizer. They will be listed hereafter but not detailed, to the exception of the CRPS \citep[Continuous Ranked Probability Score,][]{Brown1974, Matheson1976, Hersbach2000}, which is most often used. 


\textit{Discrete deterministic predictions} - These are, for example, deterministic predictions of threshold exceedances. The continuous probabilistic nature of an ensemble of analogues can be transformed into a discrete prediction by considering a fixed percentile from the distribution, which is compared to a threshold exceedance of the predictand. On the basis of a contingency table \citep{Wilks2006}, multiple scores can be processed with AtmoSwing:

\begin{itemize}
	\item Proportion correct \citep{Finley1884}
	\item Threat Score \citep{Gilbert1884}
	\item Bias
	\item False Alarm Ratio
	\item Hit Rate or Probabiliy of Detection
	\item False Alarm Rate
	\item Heidke Skill Score \citep{Heidke1926}
	\item Peirce Skill Score \citep{Peirce1884}
	\item Gilbert Skill Score or Equitable Threat Score \citep{Gilbert1884}
\end{itemize}


\textit{Continuous deterministic predictions} - These type of predictions must be evaluated with distance measures. For AMs, the provided distribution is summarized by a chosen percentile, which is compared to the predictand value. Available scores are the following:

\begin{itemize}
	\item Mean Absolute Error
	\item Root Mean Squared Error
\end{itemize}


\textit{Discrete probabilistic predictions} - Here, one works with probabilities of occurrence or probability of belonging to a certain category. The implemented scores are:

\begin{itemize}
	\item Brier Score \citep{Brier1950}
	\item ROC diagramm \citep[Relative Operating Characteristic or Receiver Operating Characteristic,][]{Mason1982}
	\item RPS \citep[Ranked Probability Score,][]{Epstein1969}
	\item SEEPS \citep[Stable Equitable Error in Probability Space,][]{Rodwell2010,Rodwell2011}
\end{itemize}


\textit{Continuous probabilistic predictions} - These type of predictions are issued in the form of the expected statistical distribution for a variable, which needs to be compared to an observed value. This is the situation one meets when using multiple analogues from AMs.

Most assessment of AMs performance use the CRPS \citep[Continuous Ranked Probability Score,][]{Brown1974, Matheson1976, Hersbach2000}. It allows evaluating the predicted cumulative distribution functions $F(y)$, for example of the precipitation values $y$ associated with the analogue situations, compared to the single observed value $y^{0}$ for a day $i$:

\begin{equation}
\label{eq:CRPS}
CRPS_{i} = \int_{0}^{+\infty} \left[ F_{i}(y)-H_{i}(y-y_{i}^{0})\right]^{2} dy
\end{equation}
where $H(y-y_{i}^{0})$ is the Heaviside function that is null when $y-y_{i}^{0}<0$, and has the value 1 otherwise; the better the prediction, the lower the score. This score is now commonly used for the evaluation of continuous variables prediction systems \citep{Casati2008, Marty2010}. It can be decomposed into several indicators, also implemented into AtmoSwing Optimizer, such as: reliability -- resolution / uncertainty \citep{Hersbach2000}, or sharpness -- accuracy \citep{Bontron2004}.

Its skill score expression is often used, with the climatological distribution of precipitation as the reference. The CRPSS (\textit{Continuous Ranked Probability Skill Score}) is thus defined as follows \citep{Bradley2011}:

\begin{equation}
\label{eq:CRPSS}
CRPSS = 1-\frac{\overline{CRPS}}{\overline{CRPS}_{clim}}
\end{equation}
where $CRPS_{clim}$ is the CRPS value for the climatological distribution. A better prediction is characterized by an increase in CRPSS.

Finally, the rank diagram \citep{Talagrand1997} and its accuracy as defined by \citet{Candille2005} are also available.


\subsubsection{The sequential calibration}
\label{sec:atmoswing-calibration}

The calibration procedure that we call ''sequential'' or ''classic'' was elaborated by \citet{Bontron2004} \cite[see also][]{Radanovics2013, BenDaoud2016}. It is a semi-automatic procedure that optimizes the spatial windows in which the predictors are compared and the number of analogues for every level of analogy. The different analogy levels (eg. the atmospheric circulation or moisture index) are calibrated sequentially. The procedure consists of the following steps \citep{Bontron2004}:

\begin{enumerate}
	\item Manual selection of the following parameters:
	\begin{enumerate}
		\item Meteorological variable
		\item Pressure level
		\item Temporal window (hour of the day)
		\item Number of analogues
	\end{enumerate}
	
	\item For every level of analogy:
	\begin{enumerate}
		\item Identification of the most skilled unitary cell (1~point for moisture variables and 4 for the geopotential height when using the S1 criteria) of the predictor data over a large domain. Every point or cell of the full domain is jointly assessed on the predictors of the current level of analogy.
		\item From this most skilled cell, the spatial window is expanded by successive iterations in the direction of greater performance gain until no improvement is reached.
		\item The number of analogue situations $N_{1}$, which was initially set to an arbitrary value, is then reconsidered and optimised for the current level of analogy.
	\end{enumerate}
	\item A new level of analogy can then be added based on other variables such as the moisture index at chosen pressure levels and hours of the day. The number of analogues for the next level of analogy, $N_{2}$, is initiated at a chosen value. The procedure starts again from step 2 (calibration of the spatial window and the number of analogues) for the new level. The parameters calibrated on the previous analogy levels are fixed and do not change. 
	\item Finally, the numbers of analogues $N_{1}$ and $N_{2}$ for the different levels of analogy are reassessed. This is performed iteratively by varying the number of analogues of each level in a systematic manner.
\end{enumerate}

The calibration is performed in successive steps on a limited number of parameters and aims at minimizing / maximizing the chosen objective function. Except for the number of analogues, previously calibrated parameters are generally not reassessed. The benefit of this method is that it is relatively fast, it provides acceptable results, and it has low computing requirements. 

Small improvements were added to this method in AtmoSwing Optimizer, then named ''classic+'', by allowing the spatial windows to do other moves, such as: (1) increase in 2 simultaneous directions, (2) decrease in 1 or 2 simultaneous directions, (3) expansion or contraction (in every direction), (4) shift of the window (without resizing) in 8 directions (including diagonals), and finally (5) all the moves described above, but with a factor of 2, 3, or more. For example, an increase by 2 grid points in one (or more) direction is assessed. This allows to skip one size that may not be optimal. These supplementary steps often result in spatial windows that are a bit different, but the performance gain is rather marginal.


\subsubsection{Variables exploration}
\label{sec:vars-explo}

The sequential calibration can also be used to explore the variables of a dataset. A list of variables, pressure levels and temporal windows can be provided and all combinations are assessed through the classic calibration. This functionality allows comparing the different variables of a dataset, while considering the effect of the pressure level and the temporal window. With this approach only one variable is assessed at a time, but multiple levels of analogy are possible, all being fixed but one. Figure \ref{figure:variable_exploration} results from such an analysis on the NR-1 reanalysis.


\subsubsection{Global optimization}
\label{sec:global-optimization}

The sequential calibration has strong limitations: (i) it cannot automatically choose the pressure levels and temporal windows (hour of the day) for a given meteorological variable, (ii) it cannot handle dependencies between parameters, and (iii) it cannot easily handle new degrees of freedom. For this reason, genetic algorithms (GAs) were implemented in AtmoSwing Optimizer to perform a global optimization of AMs. This allows to optimize all parameters jointly in a fully automatic and objective way. The method is described in \citet{Horton2017a} and an application is provided in \citet{Horton2018a}.


\subsubsection{Monte--Carlo simulations}
\label{sec:monte-carlo}

A Monte--Carlo analysis is also implemented in AtmoSwing. It performs thousands assessments of random parameters within given ranges. This method is not efficient to find the best parameters set, but helps to better understand the sensitivity of the parameters. Its relevance is however limited for AMs with multiple levels of analogy and variables. Indeed, for methods with a high number of parameters with wide authorized value ranges, the probability is too low to obtain an acceptable configuration, and thus the resulting response surface might not be representative of the actual distribution of optimal values (See examples in Sect. \ref{sec:parameters-space}). 



\section{Parameters space of AMs}
\label{sec:parameters-space}

An analysis of the parameters resulting from a Monte--Carlo simulations, the sequential calibration, and GAs was performed for the Binn station in Switzerland (Fig. \ref{figure:variable_exploration}) with the ERA-INT reanalysis (Table \ref{table:datasets}). Binn is characterized by high precipitation totals and heavy rainfall in this region was several times connected to large damages downstream. For this reason, it is a station of particular interest. The analyzes performed for this station cannot be generalized for all stations, but similar patterns were found in other locations (not shown). Moreover, the parameters space at a single station is expected to be significantly more irregular than averaged regional precipitation.

The analysis was first performed for the 2Z method with the period 2001--2010 for target, and 1981--2010 as archive. A relatively short period of 10 years was chosen to allow for 50,000 Monte--Carlo simulations. The plots in Fig. \ref{figure:monte_carlo_r1} are trunkated at the best $25^{th}$ percentile. The Monte--Carlo analysis show that the spatial window for Z needs to cover a minimal region, but can be larger than a critical size. The extent of the spatial window can thus be substantially different without affecting significantly the performance score. This issue of equifinality related to the spatial windows is discussed in \cite{Radanovics2013}. The station is usually contained within the optimal spatial domain, provided the predictors are considered at the same day that the predictand. The optimal number of analogues is better defined, although considering more analogue candidates is possible without a strong penalty in performance.

The results of the sequential calibration si also illustrated in Fig. \ref{figure:monte_carlo_r1} (squares). The calibration was first performed on the period 1981--2000 and applied to 2001--2010 (blue markers), but also calibrated directly for the 2001--2010 period (red markers). In this case, the parameters established on a different calibration period provided slightly better results. This is due to limitations of the sequential calibration that can easily get trapped in a local optima. Indeed, the resulting spatial windows are rather small here, as the algorithm stops as soon as increasing the domain do not improve the score. This might not be an issue with a low resolution reanalysis such as NR-1 (2.5\degree; Table \ref{table:datasets}), but this might become more of an issue with higher resolutions, such as ERA-INT used here (0.75\degree). Indeed, local minimas are more frequent. Moreover, the Monte-Carlo analysis provided here some better parameters sets than the sequential calibration, due to the constraint on the former to have the same spatial window for both pressure levels. 

Fourteen optimizations with GAs were performed for the same setup (7 optimizations when using the 2001--2010 period as validation -- blue triangles -- and 7 optimizations when using this period as the calibration period directly -- red triangles). The optimization with GAs was given the same number of degrees of freedom as the Monte--Carlo analysis, so no weighting of the pressure levels was considered \citep[as in][]{Horton2018a}. Thus, the superior performance of parameters optimized for the 2001--2010 period (red) is only due to an unrealized low probability of obtaining the same parameter sets randomly. GAs also result in more skillful parameters than the sequential calibration. When optimized for the 2001--2010 period (red), the parameters provide results that outperform the optimization on the 1981--2000 period (blue), but the contrary is expected to happen on the former period. Most optimizations converge to a narrow range of values, supposedly the global optimum for the given periods. The largest difference being on the minimum latitude for Z1000. The main difference with the sequential calibration is that the spatial windows are substantially larger, mainly for Z500, and they differ between pressure levels. 





For example, a Monte--Carlo analysis was performed on the PC-2Z (Table \ref{table:methods}) AM for the southeastern crests on the upper Rh\^{o}ne catchment in Switzerland, with 10,000 random selections of its parameters according to a uniform law (the analysis was also performed in other subregions of the upper Rh\^{o}ne catchment in Switzerland, but the conclusions depicted here are similar). Unlike conventional calibration, the spatial windows on Z500 and Z1000 were not necessarily overlapping. Thus, 9 parameters were varying together (8 for the spatial windows and 1 for the number of analogues)

Figure \ref{figure:monte_carlo_r1} presents the resulting scatter of random exploration of the parameters space, along with the results of the sequential calibration (red cross). Results are illustrated here for the 4 parameters defining the spatial window on Z500. Despite the high number of simulations, the upper portion of the distributions seems incomplete, and the score of the sequential calibration is not matched. Although the method is poor to find efficiently the best parameters, it is informative as to the shape of the scatter plots.

The shape of the scatter plots from Fig. \ref{figure:monte_carlo_r1} reveals a low sensitivity as to the exact location of the spatial windows. There is a maximum threshold for minimum longitudes and latitudes and, inversely, a minimum threshold for maximum latitudes and longitudes, but outside of these limits, the distribution slope is more gentle. A spatial window can thus be a bit larger than its optimal size without a significant drop in performance, as long as it includes at least one critical region. This was also observed by \citet{Bontron2004}, who noted that ''\textit{performance slowly decreases if we consider a slightly too large window, while the use of too small windows results in strong performance loss}''. The dilution of a part of the relevant synoptic information has therefore not necessarily a significant negative impact on performance, while ignoring some of this information leads to undesirable loss of performance. It is the same for the analogues number (not shown), for which, past an optimum, the upper slope of the distribution decreases slowly.

The same analysis has been conducted on the AM with 2 levels of analogy, PC-2Z-2MI (Table \ref{table:methods}), and the results on the number of analogues on the first and the second level are illustrated in Fig. \ref{figure:monte_carlo_r2}. One can see that the AM is not very sensitive to the number of analogues on the first level of analogy, when considering a second level afterwards, as long as this number is not too small. The trend on the second level is more apparent, but a large tolerance seems possible.

\section{Discussion}
\label{sec:discussion}


A version of the AM was evaluated during the project STARDEX \citep[\textit{STAtistical and Regional dynamical Downscaling of EXtremes for European regions}, see][]{Goodess2003, Stardex2005}. One of the project goals was to compare various downscaling methods for the determination of weather extremes, and the AM was selected among the most interesting from various techniques \citep{Maheras2005, Schmidli2007}. Its use as adaptation method of climate models is also the subject of a growing number of studies \citep{Zorita1999, Wetterhall2005, Wetterhall2007, Matulla2007, Chardon2014, Dayon2015}. \citet{Bliefernicht2010} obtained better results witht the AM than downscaling methods based on weather typing.

\citet{Hamill2006} used an analogy based approach on the GFS reforecasts in order to correct systematic errors in the ensemble forecasts of temperature and precipitation. Indeed, the statistical approach pointed at some bias in estimates of the numerical model, which may have been adjusted by taking into account the intrinsic local climatology from the AM. Moreover, the under-dispersion of the ensemble forecast from the numerical model has been corrected using analogues \citep{Hamill2006}. Correction of ensemble forecast under-dispersion by means of the AM is also used operationally at EDF (\'{E}lectricit\'{e} de France).

\citet{Bliefernicht2010} observed that the performance of the AM is higher for winter than for summer. The relationship between synoptic predictors and local rainfall is lower in summer, due to convective precipitations that present a higher spatial variability and that depend on other parameters. Variables describing the synoptic circulation are indeed not able to predict the location of thunderstorm cells. This was also observed by \citet{BenDaoud2010}, who set up a specific model for the summer months (June 15 to September 15).

One of the AM limitations is the need for a substantial archive of the predictand variable, for example measured precipitations, that remain to be provided by the user. Without data on several decades, the AM is not applicable. Conversely, long predictor archives are also required, but this problem is now solved with reanalysis data, which may not be perfect in terms of homogeneity, but can be considered of sufficient quality. Moreover,  reanalysis data are available all around the world, which represent a great potential for the AM, and some are now extending to the whole 20$^{th}$ century. Another issue, still about data, concerns the operational forecasting: predictors describing forecasted target situations and the ones from the archive are not fully homogeneous, as they usually don't result from the same model and resolution. It is therefore necessary to use robust variables that depend from the numerical model characteristics at a minimum extent.

Another limitation is the fact that extreme events may be under-represented in the considered sample of analogue dates. Indeed, in a limited weather archive, events with high return periods are not so numerous. Their number is certainly lower than the standard number of analogues considered, which can introduce a bias in the forecast. There are however techniques to correct this bias \citep[see][]{Marty2010}.

It is also legitimate to raise the question of the relevance of an approach based on archives of past situations in a context of climate change. The first potential issue is a possible change in atmospheric circulation. \citet{Philipp2007} observed certain trends in the synoptic atmospheric circulation over Europe, but with moderate frequencies. Moreover, the basic laws governing the atmosphere behavior will not be transformed \citep{Hewitson1996}. The assumption is that a large part of local climate change will result from changes in intensity, frequency and persistence of synoptic variables, but with other characteristics substantially similar to the present situation \citep{Hewitson1996}. Thus, if the archive of weather situations is long enough, it is reasonable to assume that a large part of future situations is already represented, even those whose frequency will change under different climatic conditions \citep{Wetterhall2005}. \citet{Dayon2015} has proven these assumptions to be accurate by showing the transferability in the future climate of the AM. They could demonstrate that the AM was able to predict the same trends in precipitations changes than Regional Climate Models. In addition, for operational use, climate change is relatively slow, and through continuous updating of the archive, the AM will incorporate new information progressively with no strong discontinuity. However, this may plea in favor of the approach proposed by \cite{BenDaoud2010} for defining the potential candidates to analogy: instead of considering a fixed period of two months before and after the target dates, one would prefer to select candidates that have approximately the same range of temperature.


\section{Conclusions and perspectives}
\label{sec:conclusions}

Processing operational forecasts by means of AtmoSwing requests in the end very low computing infrastructure and can provide useful information, such as early warning for extreme precipitation, in the case of an application in flood forecasting. The Forecaster is very flexible as it builds the desired method in a dynamic way, and can thus implement multiple variants of the AM. The connection with open access NWP model such as GFS is easy and very efficient (data are collected quickly after being available, and processed in a few minutes). The Viewer offers a user-friendly display of the forecasts, with different levels of synthesis and details. The Optimizer implements different optimization techniques, such as the sequential approach, a Monte--Carlo method, and a global optimization technique. Obviously, it is used only occasionally for a given location: for a first implementation of an AM, in case of a change in the archive, or of a substantial updating, etc.

Meanwhile, several additions would be nice to have in AtmoSwing for operational forecasting. The first one would be using outputs from multiple global NWP models within one forecast, namely making multi-models forecasts, in order to take into account the variability between various providers. In the same direction, \citet{Thevenot2004} showed the benefit of using ensembles of global NWP forecasts as input for the method (in his case the 51 traces from the EFS of ECMWF). This approach takes into account the uncertainties on predictors from the global model. Its implementation is a combination of the selected analogue days associated with each of the traces. Rainfall distribution is then established on all analogues. The forecast on the ensemble was found to be more accurate than the deterministic control for a lead time of 4 days and more \citep{Thevenot2004}. 

Next, a bias correction should be implemented. \citet{Marty2010} has indeed observed that the frequency of the forecasted days without precipitation was biased and underestimated the actual frequency of zero precipitation. On the contrary, the frequency of the forecasted days with precipitation overestimated the observed frequencies. On this basis, \citet{Marty2010} proposed a bias correction technique, that should be implemented as well. This issue occurs in operational forecasting and was not observed in perfect prognosis.

As it was shown in the historical section, the AM evolves, with the availability of new data, computer facilities and progress in NWP models, and still proves to bring complementary information on predictands like precipitation, for example at long lead time. Its interest in climatological downscaling has not been addressed in this paper but should be mentioned. However, there remain still many possibilities to be explored. Amongst them, one can mention:

\begin{itemize}
	\item an optimization per season in order to get parameterizations specific to the leading processes during the period in question;
	\item optimizations specific for extreme events, with an objective function tailored to the determination of the most critical situations;
	\item a better insight in the role of the length of the archive, by using long reanalyses over the $20^{th}$ century;	
	\item a weighting of the predictor grids \citep[see][]{Bliefernicht2010};
	\item assessment of potential indicators based on the properties of the distribution of all analogues or the 10 best, for example;
	\item assessment of the relevance of an automatic interpretation of the distribution in order to provide the most likely expected value;
\end{itemize}


\section*{Code availability}

AtmoSwing is open source, under the CDDL license. It is developed under the Git distributed revision control, and the source code can be found at:

\begin{itemize}
	\item AtmoSwing \citep{Horton2018c}: https://github.com/atmoswing/atmoswing/
	\item AtmoSwing R tools \citep{Horton2018d}: https://github.com/atmoswing/tools-r/
	\item AtmoSwing Python tools \citep{Horton2018e}: https://github.com/atmoswing/tools-py/
	\item Homepage: http://www.atmoswing.org
\end{itemize}


\section*{Acknowledgements}
Thanks to Lucien Schreiber and Richard Metzger for their programming advices and to Renaud Marty for his active involvement in testing AtmoSwing against his code base. Calculations were performed on UBELIX (http://www.id.unibe.ch/hpc), the HPC cluster at the University of Bern. 

Precipitation time series were provided by MeteoSwiss. The NCEP/NCAR reanalysis was provided by the NOAA/OAR/ESRL PSD, Boulder, Colorado, USA, at http://www.esrl.noaa.gov/psd/. ERA-interim was obtained from the ECMWF Data Server at http://apps.ecmwf.int/datasets/. 



\bibliography{references}

\clearpage

% Sizes:  https://www.elsevier.com/authors/author-schemas/artwork-and-media-instructions/artwork-sizing

\begin{figure*}[t]
	\includegraphics[width=14cm]{figures/selection_variables_optim.pdf}
	\caption{Performance score (CRPSS) of the 30 best variables from the NCEP/NCAR reanalysis dataset, when considered separately (no combination), for the Chablais region and the southeast ridges. The analogy criteria is S1 when there is an asterisk next to the variable name, and RMSE otherwise. Color illustrates the variable type: green = atmospheric circulation, blue = moisture, orange = temperature, yellow = radiation, purple = vertical velocity, and gray = other. SLP stands for sea level pressure, and Z for geopotential height. The blue square indicates the Binn station, which is analyzed in more details later on.}
	\label{figure:variable_exploration}
\end{figure*}

\begin{figure}[t]
	\includegraphics[width=9cm]{figures/fig01.pdf}
	\caption{Proposed structure for naming the parameterizations of the AM.}
	\label{figure:nomenclature}
\end{figure}

\begin{figure}[t]
	\includegraphics[width=9cm]{figures/flowchart.pdf}
	\caption{Simplified flowchart of the AM implementation in AtmoSwing.}
	\label{figure:flowchart_modules_atmoswing}
\end{figure}

\begin{figure*}[t]
	\includegraphics[width=19cm]{figures/code_diagram.pdf}
	\caption{Simplified illustration of the main classes or objects involved in the core of the AM processing in AtmoSwing. The processor class interacts with parent classes that can represent different entities, such as different reanalysis datasets, predictand, criteria, scores, and in different contexts: calibration, forecasting, and downscaling. The items in green are only available in the Optimizer, the ones in blue, in the Forecaster, and the ones in Orange, in the Downscaler. The area represents the spatial window and the time array a list of candidate dates (from preselection or previous analogy levels). The links to the parameters illustrate the dynamic definition of the different types by the parameters from the XML file.}
	\label{figure:code_diagram}
\end{figure*}

\begin{figure}[t]
	\includegraphics[width=9cm]{figures/fig06.png}
	\caption{Graphical user interface of the Forecaster module. A list of different parameterizations is being processed.}
	\label{figure:atmoswing-forecaster-gui}
\end{figure}

\begin{figure*}[t]
	\includegraphics[width=19cm]{figures/fig07.jpg}
	\caption{Graphical user interface of the Viewer module (Elevation data from The Shuttle Radar Topography Mission (SRTM), and hydrological network from SwissTopo).}
	\label{figure:atmoswing-viewer-gui}
\end{figure*}

\begin{figure*}[t]
	\includegraphics[width=19cm]{figures/fig08.jpg}
	\caption{Visualization of multiple lead times on the map (Elevation data from the SRTM, and hydrological network from SwissTopo).}
	\label{figure:atmoswing-viewer-snail}
\end{figure*}

\begin{figure}[t]
	\includegraphics[width=9cm]{figures/fig09.png}
	\caption{Visualization of the forecasted time series for an event at the Binn station (Fig. \ref{figure:variable_exploration}) in October 2018.}
	\label{figure:atmoswing-viewer-timeseries}
\end{figure}

\begin{figure}[t]
	\includegraphics[width=9cm]{figures/fig10.png}
	\caption{Visualization of the forecasted precipitation distribution for a given lead time for an event at the Binn station (Fig. \ref{figure:variable_exploration}) in October 2018.}
	\label{figure:atmoswing-viewer-distribution}
\end{figure}

\begin{figure*}[t]
	\includegraphics[width=19cm]{figures/fig11.jpg}
	\caption{Example of parameters values for 2Z (Table \ref{table:methods}) for the precipitation at the Binn station (Fig. \ref{figure:variable_exploration}) on the period 2001--2010. The parameters are the extent (min/max longitude/latitude) of the spatial windows for the geopotential height at 500 and 1000~hPa, and the number of analogues. The location of the station is represented by the green vertical bar in the plots. The circles represent random parameters from the Monte--Carlo analysis. The plots are trunkated at the $25^{th}$ best percentiles of 50,000 realizations. Squares are the results of the sequential calibration and triangles result from genetic algorithms. Markers in blue represent parameters optimized for the period 1981--2000 and applied to 2001--2010. Markers in red represent parameters optimized directly for the period 2001--2010.}
	\label{figure:monte_carlo_r1}
\end{figure*}

\begin{figure*}[t]
	\includegraphics[width=19cm]{figures/fig12.jpg}
	\caption{Same as Fig. \ref{figure:monte_carlo_r1} but for 2Z-2MI (Table \ref{table:methods}). Results are shown for both levels of analogy (geopotential height and moisture index).}
	\label{figure:monte_carlo_r2}
\end{figure*}

\clearpage


\begin{table*}[t]
	\caption{Reanalysis datasets that can be read by AtmoSwing.}
	\begin{center}
		\begin{tabular}{ccccccc}
			\hline
			\multirow{2}{*}{\textbf{Name}} & \multirow{2}{*}{\textbf{Institution}} & \textbf{Period} & \textbf{Output} & \textbf{Model} & \textbf{Model} & \textbf{Type of}\\ 
			&& \textbf{of record} & \textbf{resolution} & \textbf{resolution} & \textbf{vintage} & \textbf{input} \\ 
			\hline 
			\textbf{NR-1} & NCEP, NCAR & 1948 -- present & 2.5\degree x 2.5\degree & T62 ($\sim$1.88\degree), L28 & 1995 & full \\
			\textbf{NR-2} & NCEP, DOE & 1979 -- present & 2.5\degree x 2.5\degree & T62 ($\sim$1.88\degree), L28 & 2001 & full \\
			\textbf{ERA-INT} & ECMWF & 1979 -- present & 0.75\degree x 0.75\degree & TL255 ($\sim$0.70\degree), L60 & 2006 & full \\
			\textbf{20CR-2c} & NOAA-CIRES & 1851 -- 2014 & 2\degree x 2\degree & T62 ($\sim$1.88\degree), L28 & 2008 & surface \\
			\textbf{CFSR} & NCEP & 1979 -- present & 0.5\degree x 0.5\degree & T382 ($\sim$0.31\degree), L64 & 2009 & full \\
			\textbf{JRA-55}  & JMA & 1958 -- present & 1.25\degree x 1.25\degree & TL319 ($\sim$0.36\degree), L60 & 2009 & full \\
			\textbf{JRA-55C}  & JMA & 1958 -- 2015 & 1.25\degree x 1.25\degree & TL319 ($\sim$0.36\degree), L60 & 2009 & conventional \\
			\textbf{ERA-20C} & ECMWF & 1900 -- 2010 & 1\degree x 1\degree & TL159 ($\sim$1.13\degree), L91 & 2012 & surface \\
			\textbf{MERRA-2} & NASA GMAO & 1980 -- present & 0.625\degree x 0.5\degree & 0.625\degree x 0.5\degree, L72 & 2014 & full \\ 
			\textbf{CERA-20C} & ECMWF & 1901 -- 2010 & 1\degree x 1\degree & T159 ($\sim$1.13\degree), L91 & 2016 & surface \\
			\hline 
		\end{tabular} 
	\end{center}
	\label{table:datasets}
\end{table*}

\begin{table*}[t]
	\caption{Some existing analogue methods, listed by increasing complexity. P0 is the preselection (PC: on calendar basis, that is $\pm 60$ days around the target date), L1, L2 and L3 are the subsequent levels of analogy. N1, N2 and N3 are the number of analogues to select at each level of analogy. The meteorological variables are: Z -- geopotential height, T -- air temperature, W -- vertical velocity, MI -- moisture index, which is the product of the relative humidity at the given pressure level and the total water column, MF -- moisture flux, which is the product of MI with the wind intensity. The analogy criterion is S1 for Z and RMSE for the other variables.}
	\begin{center}
		\begin{tabular}{ccccccccl}
			\hline
			\textbf{Type} & \textbf{P0} & \textbf{L1} & \textbf{N1} & \textbf{L2} & \textbf{N2} & \textbf{L3} & \textbf{N3} & \textbf{Reference} \\ 
			\hline 
			\textbf{PC-2Z} & PC & Z1000@12h & 50 &&&&& \citealt{Bontron2004} \\
			&& Z500@24h &&&&&& \\
			\hline 
			\textbf{PC-4Z} & PC & Z1000@06h & {\raise.17ex\hbox{$\scriptstyle\sim$}}27 &&&&& \citealt{Horton2018a} \\
			&& Z1000@30h &&&&&& \\
			&& Z700@24h &&&&&& \\
			&& Z500@12h &&&&&& \\
			\hline 
			\textbf{PC-2Z-2MI} & PC & Z1000@12h & 70 & MI850@12h & 30 &&& \citealt{Bontron2004} \\
			&& Z500@24h && MI850@24h &&&& \\
			\hline 
			\textbf{PC-2Z-2MI} & PC & Z1000@06h & 75 & MI925@06h & 30 &&& \citealt{Marty2010} \\
			&& Z500@18h && MI925@18h &&&& \\
			\hline 
			\textbf{PC-2Z-2MF} & PC & Z1000@06h & 60 & MF700@06h$^{\dagger}$ & 25 &&& \citealt{Marty2010} \\
			&& Z500@18h && MF700@18h &&&& \\
			\hline 
			\textbf{PC-4Z-2MI} & PC & Z1000@30h & {\raise.17ex\hbox{$\scriptstyle\sim$}}63 & MI700@24h & {\raise.17ex\hbox{$\scriptstyle\sim$}}24 &&& \citealt{Horton2018a}\\
			&& Z850@12h && MI600@12h &&&& \\
			&& Z700@24h &&&&&& \\
			&& Z400@12h &&&&&& \\
			\hline 
			\textbf{PT-2Z-4MI} & T925@36h & Z1000@12h & 70 & MI925@12h & 25 &&& \citealt{BenDaoud2016} \\
			& T600@12h & Z500@24h && MI925@24h &&&& \\
			&&&& MI700@12h &&&& \\
			&&&& MI700@24h &&&& \\
			\hline 
			\textbf{PT-2Z-10MI} & T925@36h & Z1000@12h & 70 & MI925@06-30h & 25 &&& \citealt{BenDaoud2010} \\
			& T600@12h & Z500@24h && MI700@06-30h &&&& \\
			\hline 
			\textbf{PT-2Z-4W-4MI} & T925@36h & Z1000@12h & 170 & W850@06h & 70 & MI925@12h & 25 & \citealt{BenDaoud2016} \\
			& T600@12h & Z500@24h && W850@12h && MI925@24h && \\
			&&&& W850@18h && MI700@12h && \\
			&&&& W850@24h && MI700@24h && \\
			\hline 
		\end{tabular} 
	\end{center}

	$\dagger$ or MF925@06h+18h as an alternative
	\label{table:methods}
\end{table*}


\end{document}