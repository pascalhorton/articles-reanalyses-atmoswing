\documentclass[review]{elsarticle}
%\documentclass[5p]{elsarticle}

\usepackage{lineno,hyperref,gensymb,multirow}
\modulolinenumbers[5]

\journal{Environmental Modelling \& Software}



% TODO: wider litterature review
% TODO: show scaling with multiple cores
% TODO: more technical stuff (e.g. classes + schemas)
% TODO: Raspberry Pi

% TODO: rewrite abstract
% TODO: add more references
% TODO: remove appendix ?
% TODO: add all reanalysis datasets
% TODO: add forecasts performances
% TODO: review: While the authors show a good command of the Analogue Technique and of its applications, it is not clear from the manuscript which predictors should be used for the forecast of alpine precipitations. The authors present two sets, that of Bontron (2004) and of Horton et al. (2012). An evaluation (or a summary, if already done elsewhere) of the relative merits of the two methods should be shown,
% TODO: relative merits of the metrics used (S1 or RMSE) are not explained
% TODO: article doesn't present any evaluation or validation of the precipitation fields/data or alerts provided by AtmoSwing
% TODO: the article is too general and descriptive and should detail the specifics of the present implementation of the Analogue Technique.
% TODO: Another point (though not a reason for rejection) is about the practical use for forecasters: as the authors rightly pointed out, it is impossible to apply analogue techniques directly on NWP forecasts of meteorological parameters, since the analogues are provided by other models, with different resolution. A coherent (I.e with the same model version and resolution) and long enough period of NWP forecasts can be hard to come by, especially for rare episodes. This may restrain the practical use of AtmoSwing for operational precipitation and flood forecasts. Maybe the authors could comment on that?


%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
%\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\begin{frontmatter}

\title{AtmoSwing: Analogue Technique Model for Statistical Weather forecastING and downscalING}


\author[unibe,unil,terranum]{Pascal Horton\corref{correspondingauthor}}
\cortext[correspondingauthor]{Corresponding author}
\ead{pascal.horton@giub.unibe.ch}

\author[grenoble]{Charles Obled}
\author[unil]{Michel Jaboyedoff}
\author[unibe]{Rolf Weingartner}

\address[unibe]{University of Bern, Oeschger Centre for Climate Change Research, Institute of Geography, Bern, Switzerland}
\address[unil]{University of Lausanne, Institute of Earth Sciences, Lausanne, Switzerland}
\address[terranum]{Terranum SARL, Bussigny, Switzerland}
\address[grenoble]{Universit\'{e} de Grenoble-Alpes, LTHE, Grenoble, France}



\begin{abstract}
Analog methods (AMs) allow predicting local meteorological variables of interest (predictand), such as the daily precipitation, on the basis of synoptic variables (predictors). They rely on the fact that similar meteorological influences are likely to result in similar local effects. This statistical relationship is thus based on archives of observed data, and used in order to operationally forecast the coming days, or to evaluate future conditions under a changing climate.

AtmoSwing is an open source software that implements different AM variants in a very flexible way, so that different variants can be handled dynamically, by parameterization through XML files. It is made of 3 tools: the Forecaster to perform operational forecasts, the Viewer to display the results, and the Optimizer to establish the relationship between the predictand and predictors. 

The Forecaster handles every required processing internally, such as predictors downloading and reading, grid interpolation, analogy sorting, without external scripts or file conversion. The processing of a forecast is extremely lightweight in terms of IT infrastructure; it can indeed run on almost any computer.

The Viewer displays the forecasts in an interactive GIS environment. It contains several layers of syntheses and details in order to provide a quick overview of the potential critical situations in the coming days, as well as the possibility for the user to go into the details of the forecasted predictand and criteria distributions. Several tips coming from the literature are provided in order to help interpreting the forecasts.

The Optimizer integrates the common semi-automatic sequential approach, as well as Monte\textendash Carlo analyses, and a global optimization technique by means of Genetic Algorithms. 

\end{abstract}

\begin{keyword}
analogue method, precipitation, downscaling, forecasting
\end{keyword}

\end{frontmatter}

\linenumbers


\section{Introduction}

Approaches based on the concept of analogy is rather widespread in different domains of sciences or engineering. In hydrometeorology it consists in retrieving atmospheric situations from the past that can be considered similar to the situation at hand and therefore with consequences that may be expected similar. Consequences can be local variables of interest, such as the occurrence of fog, favourable conditions for avalanches, the wind intensity, or the precipitation amount. It relies on the idea expressed by \citet{Lorenz1956, Lorenz1969} that similar situations in terms of atmospheric circulation are likely to lead to similar local weather. The approach requires at least two concurrent archives: one describing the situation through different variables, called predictors, and another one providing the value of the local variable of interest, called predictand.

Usually, the predictand values could be derived by modeling the chain of processes linking the predictors to the predictand. The processes involved range from large scale dynamical states of the atmosphere down to very small scale microphysical processes, requiring models that are extremely complex, data-demanding, and time consuming. Conversely, given an appropriate set of predictors archives, enough situations analogous to a target one could be found so that reasonable values will be obtained for the predictand, at a reasonable coding and computing-time costs. This is particularly true for a predictand much required in hydrometeorological applications, namely the precipitation amount over a given domain and time duration. Incidentally, the forecast will be proposed as a statistical distribution based on the values taken by the predictand in the set of analogs selected, unless one considers only the single best analog, which may not prove the most efficient \citep{Bontron2005}.

Analogue methods (AMs) are used in two different kind of approaches \citep{Rummukainen1997}: perfect prognosis, for which the statistical relationship is calibrated based on observed predictors, and model output statistics, for which the relationship is calibrated against the outputs of a specific climate or numerical weather prediction (NWP) model. It is often used to predict daily precipitation, either in an operational forecasting context \citep[e.g.][]{Guilbaud1997, Bontron2005, Hamill2006, Bliefernicht2010, Marty2012, Horton2012, Hamill2015, BenDaoud2016} or a climate downscaling context \citep[e.g.][]{Radanovics2013, Chardon2014, Dayon2015, Raynaud2016b}. Other predictands are also considered, such as precipitation radar images \citep{Panziera2011,Foresti2015a}, temperature \citep{Radinovic1975, Woodcock1980, Kruizinga1983, DelleMonache2013, Caillouet2016, Raynaud2016b}, wind \citep{Gordon1987, DelleMonache2013, DelleMonache2011, Vanvyve2015, Alessandrini2015, Junk2015, Junk2015c}, solar radiation or power production \citep{Alessandrini2015a, Bessa2015, Raynaud2016b}, snow avalanches \citep{Obled1980, Bolognesi1993}, and the trajectory of tropical cyclones \citep{Keenan1981, Sievers2000, Fraedrich2003}. \citet{Guilbaud1997} performed a literature review about the use of the AM in long-term forecasting and identified operational applications for monthly forecasts in many countries, including Canada \citep{Shabbar1986},  Hungary \citep{Toth1989}, the Netherlands \citep{Nap1981}, and England \citep{Murray1974}, as well as seasonal forecasts: \citet{Barnett1978}, \citet{Bergen1982} and \citet{Livezey1988}.

In operational forecasting, they have been used mainly by practitioners, notably hydropower companies \citep{Desaint2008a,BenDaoud2009,Obled2014} or flood forecasting services in France and Switzerland \citep{Marty2010,GarciaHernandez2009b,Horton2012}. They should however not be considered as a substitute for NWP models, but as a complement in order to get a fast and partly independent forecast that is known to be accurate several days in advance. They therefore enrich the analysis of a potential critical situation for flood forecasting, for example, and are very interesting in early warning.

The present work does not present a new method, but a software, named AtmoSwing, implementing AMs in a versatile and efficient way. Versatile, as it allows building AM structures in a dynamic way, through the use of XML files, and because the code is written with an object-oriented architecture. Efficient, as it is written in C++ and allows parallel computing. AtmoSwing is made up of different modules targeted either for operational forecasting (the Forecaster and the Viewer) or for climate impact studies (the Downscaler). Additionally it provides a module to calibrate the different parameters of the method, namely the Optimizer. AtmoSwing is continuously evolving and has been used in \citet{Horton2012, Horton2017a, Horton2017b, Horton2018a} and \citet{Horton2018b}.

Some existing AMs designed for daily precipitation will first be described along with the required data (Sect. \ref{sec:data_methods}) and the software will then be presented (Sect. \ref{sec:atmoswing}) and its modules detailed: the Forecaster (Sect. \ref{sec:forecaster}), the Viewer (Sect. \ref{sec:viewer}), the Downscaler (Sect. \ref{sec:downscaler}), and the Optimizer (Sect. \ref{sec:optimizer}). The conclusion (Sect. \ref{sec:conclusions}) provides some additional perspectives for future developments of AtmoSwing. 


\section{Data and methods}
\label{sec:data_methods}


\subsection{Data}
\label{sec:data}

AMs generally require three datasets: one of the historical predictand values, one of the historical predictor values for the same period and another one of the predictors describing the target situation.

The predictand is often daily time series. It can have a higher temporal resolution, such as 6-houry, but not higher than the time step of the predictors. The most used predictand is the daily precipitation, usually averaged over subregions in order to smooth local effects \citep{Obled2002, Marty2012}. These time series are frequently normalized by the precipitation value for a return period of 10~years \citep{Djerboua2001}. This normalization allows for an easier comparison between subregions subject to different precipitation regimes, and thus to better identify the most important contributions.

The predictors archive is often a global atmospheric reanalysis dataset, which provides gridded large-scale variables at any location in the world. Reanalyses are produced using a single version of a data assimilation system coupled with a forecast model constrained to follow observations over a long period. They provide multivariate outputs that are physically consistent, which contain information in locations where few or no observations are available, also for variables that are not directly observed \citep{Gelaro2017}. Even though reanalyses are considered as very accurate in a data-rich region such as Europe, they can have a non-negligible impact on the skill of the prediction that can be even higher than the choice of the predictor variables \cite{Dayon2015, Horton2018b}. AtmoSwing can read the native files of ten reanalyses (Table \ref{table:datasets}), and others can be easily added thanks to the encapsulation of the dataset characteristics in the objects. Users can find recommendations for the selection of a reanalysis in \cite{Horton2018b}. Other predictor archives can also be used, such as Sea Surface Temperature \citep[SST, ][]{Reynolds2007}. \citet{Bontron2004} proposed that the minimum length of the archive should be 30 years to predict usual situations, and 40 years or more for intense events.

The predictors dataset describing the target situation varies according to the application of the AM. For operational forecasting (Sect. \ref{sec:forecaster}) they are outputs of NWP models, such as GFS \citep[Global Forecast System,][]{Kanamitsu1991,Kanamitsu1989}, which is operated by NCEP and NOAA. For climate impact studies (Sect. \ref{sec:downscaler}), they are outputs of general circulation models (GCMs) or regional climate models (RCMs).


\subsection{Analog methods}
\label{sec:method}

AtmoSwing does not rely on a single variant of the AM, but can implement different variants. A non-exhaustive selection will be presented hereafter, focusing on the prediction of daily precipitation. Some early findings and choices will also be summarized to justify the present structure of this family of AMs, such as the use of raw data instead of principal components.


\subsubsection{Principles}

The AM is based on the principle that two similar synoptic situations may produce similar local effects \citep{Lorenz1956}. The perfect analogy does not exist, but sufficiently similar situations leading to similar effects can be identified. Thus, two states of the atmosphere that are alike are called analogues \citep{Lorenz1969}. To be relevant, this analogy must be selected by optimizing the following elements:

\begin{itemize}		
	\item The meteorological variables (predictors) must contain synoptic scale information having a direct or indirect dependency with the target predictand.
	\item The pressure level, or height, at which the predictor is selected.
	\item The spatial window is the domain on which predictors are compared. The ideal size of this area is that which maximizes the useful information and minimizes noise.
	\item The temporal window is the hour(s) of the day at which the predictors are considered.
	\item The analogy criterion, needed to compare the variables on the chosen spatial and temporal windows, is a distance measure, used to rank observed situations according to their degree of similarity with the target situation.
	\item Eventual weights between the predictors \cite[e.g.,][]{Horton2017b, Junk2015}.
	\item The optimal number of analog situations, which is the best compromise in order to take into account local variability and maximize useful synoptic information.
\end{itemize}

Because of the chaotic nature of the atmosphere, two analog situations quickly diverge over time \citep{Lorenz1969}. Thus, the AM has strong limitations regarding the temporal extrapolation \citep{Bontron2004}. Numerical models being more capable of simulating the dynamic evolution of the atmosphere, the temporal extrapolation of the synoptic variables is left to them. The search for analogy aims thus at connecting the forecasted synoptic situation with a local predictand (temperature, precipitation, etc), which is more difficult to simulate by numerical models.








\subsubsection{Present structure}

Although multiple variations of the AM exist, they generally share the same basics and the same structure. For example, let's say we want here to forecast the daily precipitation for a target day, at a defined lead time. The generic structure is the following:

\begin{enumerate}
	\item Preselection: to cope with seasonal effects, candidate dates are extracted from the archive within a period of four months centered around the target date, for every year of the archive. Alternatively, the candidate dates can be selected based on similar air temperature \citep{BenDaoud2010}.
	
	\item First level of analogy: $N_{1}$ dates are subsampled within all the candidates provided by the preselection, by means of an analogy ranking. The first level of analogy is always based on the atmospheric circulation when it comes to precipitation prediction. The similarity of the atmospheric circulation of the target date with the candidate situations is thus assessed on the geopotential by means of the S1 criteria \citep[Eq. (\ref{eq:S1}), ][see also Sect. \ref{sec:method:references}]{Teweles1954, Drosdowsky2003}, which is a comparison of gradients, over a certain spatial gridded window.
	
	\begin{equation}
	\label{eq:S1}
	S1=100 \frac {\displaystyle \sum_{i} \vert \Delta\hat{z}_{i} - \Delta z_{i} \vert}
	{\displaystyle \sum_{i} max\left\lbrace \vert \Delta\hat{z}_{i} \vert , \vert \Delta z_{i} \vert \right\rbrace }
	\end{equation}
	where $\Delta \hat{z}_{i}$ is the forecast geopotential height difference between the \textit{i}th pair of adjacent points from the grid of the target situation, and $\Delta z_{i}$ is the corresponding observed geopotential height difference in the candidate situation. The differences are processed separately in both directions. The smaller the S1 values, the more similar the pressure fields.
	
	The $N_{1}$ dates with the lowest values of S1 are considered as analogs, in terms of the general circulation, to the target day. The number of analogs, $N_{1}$, is a parameter to calibrate.
	
	\item Subsequent level(s) of analogy: beyond the similarity of airflows, one may look for similarities in other variables of interest, such as moisture variables. Therefore, the $N_{1}$ analogs are subsampled once again on the basis of another variable in order to obtain a lower number of analog dates, $N_{2}$. The S1 criterion is usually not relevant for other predictors that the atmospheric circulation. Classic criteria represent absolute distances: Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE), the latest being most often used.
	
	This process can be repeated, by subsampling a decreasing number of analogs, $N_{i}$, according to various meteorological variables.
	
	\item Probabilistic forecast: then, the (e.g. daily) observed precipitation amount (or another predictand of interest) of the $N_{i}$ resulting dates provide the empirical conditional distribution considered as the probabilistic forecast for the target day. The empirical frequencies are processed for every value of the predictand, after classification, based on the Gringorten parameters \cite[for a Gumbel or exponential law; see][]{Gringorten1963} and a probabilistic model can be fitted \citep[e.g. Gamma function,][]{Obled2002}. The forcast is finally often synthetized by the percentiles 20, 60 and 90~\% \citep{Guilbaud1997, Guilbaud1998}.
	
\end{enumerate}


\subsubsection{Proposed nomenclature}

Variants of the AM parameterization are numerous and it is not always easy to reference them in a short and descriptive way. We thus propose a basic nomenclature (Fig. \ref{figure:nomenclature}) in order to express the structure into a simple identifier. This one cannot describe all the parameters of the AM, but quickly illustrate the structure of the implementation. This is particularly useful when working with a global optimization method, where nothing is fixed but the very structure of the AM.

The naming contains different blocs (separated by an hyphen) for the various levels of analogy. It starts with the specification of the preselection (P; can be omitted when comparing AMs with the same preselection approaches), which can be nowadays of 2 types:
\begin{itemize}
	\setlength\itemsep{-2px}
	\item C: calendar period ($\pm 60$ days around the target date)
	\item T: based on air temperature \citep{BenDaoud2010}
\end{itemize}

Then, the following levels of analogy are listed, which may start with an optional A (for analogy). For every level of analogy, the number of variables used (combination of atmospheric levels and time of observation) is first provided, and then the short name of the variable is given (according eg to ECMWF conventions; in upper case), for example:
\begin{itemize}
	\setlength\itemsep{-2px}
	\item Z : geopotential (circulation)
	\item TPW : total precipitable water
	\item RH : relative humidity
	\item V : wind velocity
	\item W : vertical velocity
	\item MI : moisture index (TPW * RH)
	\item MF : moisture flux (V * TPW * RH)
\end{itemize}

In order to keep the identifier simple, no value of atmospheric level neither time of observation is specified. Moreover, the analogy criterion is not specified and is supposed to be S1 for Z and RMSE for the other variables. If anything changes from these conventions, it can be noted as a flag. The flag (lower case) can also give other information, such as the optimization method:
\begin{itemize}
	\setlength\itemsep{-2px}
	\item sc : sequential calibration (can be omitted as considered as default, see Sect. \ref{sec:atmoswing-calibration})
	\item go (or just ''o'') : global optimization (by means of genetic algorithms for example)
\end{itemize}

This nomenclature can be adapted to specific needs, or simplified for a better readability (eg. by removing the specification of the preselection). For example, one of the most used parameterization established by \citet{Bontron2004} is composed of a first level of analogy on the geopotential height and a second on the moisture index and can thus be codified as PC-2Z-2MI. Other examples are provided in the following section.


\subsubsection{Common variants for precipitation prediction}
\label{sec:method:references}




%\citet{Lorenz1969} introduced the concept and established the basis of the AM. He considered looking for analogs on the geopotential field (at 200, 500 and 850~hPa) with a corrected Euclidean distance averaged on the 3 levels. 

%The use of the AM for operational forecasting of daily precipitation originates in the work of \citet{Duband1970, Duband1974, Duband1981}. It was then designed for operational forecasting at EDF in order to better manage water resources and flood risks. The geopotential height at 700~hPa and 00~h was used for its higher stability than the sea level pressure (SLP) field, and its sensitivity to the atmospheric disturbances \citep{Guilbaud1997}. However, the SLP at 06~h was also introduced for determining the precipitation intensity, as well as the temperature at 700~hPa as indicator of the thermal state of the air mass \citep{Duband1974}. The data were then based on 37 radiosounding over Europe and condensed by a principal component analysis. The first 25 analogs on the geopotential at 700~hPa were considered, and multiple local regressions between precipitation, SLP, and the temperature at 700~hPa were established on these analogs before being applied to the target situation \citep{Guilbaud1997}. The archives were split by season to consider comparable situations in terms of distribution of solar energy \citep{Lorenz1969}. This initially rigid division into seasons was then transformed into a moving selection of more or less two months around the target date. The forecast was then performed only on the basis of radiosonde observations and was temporally extrapolated to the two following days. After a few years, this statistical temporal extrapolation was abandoned in favor of a statistical adaptation using synoptic predictors taken from a numerical model, allowing a forecast over the following 4~days.

%Thereafter, the geopotential was considered at 1000~hPa and 700~hPa and the analogs selection was done in two stages: first according to an Euclidean distance in the space of the principal components of the geopotential field at 700~hPa, and then according to a correlation criterion (on the geopotential field at 700 and 1000~hPa, as well as on the thickness between these two levels) in order to remove days close in distance but too dissimilar in pattern \citep{Guilbaud1997}. The local regression approach to determine precipitation was eventually abandoned in favor of the direct probabilistic forecasting (synthesized by the percentiles 20, 60 and 90~\%), as it is performed today by interpolating linearly over the cumulative empirical distribution of daily precipitation measured at the analog days \citep{Guilbaud1997, Guilbaud1998}.

%\citet{Wilson1980} sought the 20 best analogs on the geopotential field at 500 and 1000~hPa using the Teweles\textendash Wobus (S1) criterion (Eq. \ref{eq:S1}), which allows for a comparison of the gradients and thus an analogy of the atmospheric circulation. This work has demonstrated the best performance of the AM compared to classical regression based approaches. \citet{Woodcock1980} used the same criterion on the SLP fields to select 50~analogs in order to predict maximum daily temperatures. After comparing S1 to other criteria from the literature, or combinations of these, \citet{Guilbaud1998} confirmed that S1 is the most efficient. They also pointed out the benefit of using 2 atmospheric levels, 1000~hPa (Z1000) and 700~hPa (Z700) or 500~hPa (Z500), instead of one (also instead of the thickness), and to also consider 2 temporal windows, 00~h and 24~h \citep{Obled2002}. 

%\citet{Guilbaud1997} stopped using PCA in order to work directly with the raw data interpolated on grids, which resulted in an improvement, especially when considering the S1 criterion instead of the Euclidean distance. The number of analogs considered was 50. When using multiple predictors, they combined the criteria values calculated on each atmospheric level and each temporal window using an arithmetic mean.

%At the dawn of the new millennium, \citet{Bontron2004} could benefit from a real breakthrough, the newly available NCEP/NCAR reanalysis data. This dataset being more homogeneous, much longer, and containing more variables than what was previously used, he could systematically assess a large selection of variables in the AM combined with different criteria. He thus confirmed the interest of the geopotential height along with the S1 criterion for the first level of analogy. He has also shown that the choice of the temporal window (time of observation) has a higher importance than the atmospheric level for the performance of the AM for daily precipitations. By assessing multiple combinations of atmospheric levels and temporal windows, he concluded that the coupled geopotential heights at 1000~hPa (Z1000) \& 12~h and 500~hPa (Z500) \& 24~h provided the best performance for the studied region (Table \ref{table:methods}).

%\citet{Mandon1985} tried to introduce a second level of analogy and assessed different variables, such as wind, moisture, air temperature, surface temperature of the Mediterranean, the product of wind and the 700~hPa moisture, as well as a second barometric criteria differentiated according to the season. \citet{Vallee1986} continued to work on the second level of analogy and considered the wind at 700~hPa \& 12~h in order to improve heavy precipitation events for a region in France susceptible to southerly flows.

%\citet{Bontron2004} also assessed several variables for the second level of analogy and identified the moisture variables (precipitable water and relative humidity) and vertical velocity to be the most relevant. Finally, he found that a moisture index made of the product of relative humidity at 850~hPa (RH850) and total precipitable water (TPW) gave the best performance (Table \ref{table:methods}). He noted the relevance of defining different spatial windows for each region, rather than a single window for the entire territory. These windows are more able to represent the specific atmospheric influences for each region. He also highlighted the dependency between the optimal number of analogs and the archive size: the shorter the archive, the lower the number of analogs.

%By varying the resolution of the predictors grids, \citet{Bontron2004} concluded that the performance increase is not significant for the analogy of atmospheric circulation below a resolution of 5\degree. However, it seems more important for the second level of analogy on moisture, which are more local variables. \citet{BenDaoud2010} assessed the European reanalysis ERA-40 \citep{Uppala2005} with a resolution of 1.125\degree. He identified a slight performance improvement, but not substantial enough to really justify an archive change \citep{BenDaoud2008}.

%\citet{Gibergans-Baguena2007} implemented the AM for daily precipitation forecasts in Catalonia. They considered the geopotential at 700 and 1000~hPa, and the thickness between these two levels, to search for analogy of circulation, and then applied a second selection on local data from radiosonde: stability indexes, precipitable water, temperature, etc.




Some examples of parameterization of the most used or the most recent AM variants are provided hereunder. Some of these are more specific for a certain region and may not be relevant for others, and some perform better depending on the lead time. An extended history of the method's origin and its early evolution can be found in Appendix \ref{app:evolution}.

The basis of the method was introduced by \citet{Lorenz1969}, who considered the analogy of the geopotential field on different pressure levels. In addition, the analog situations were to belong to the same period of the year to be comparable in terms of distribution of solar energy. This preselection was later implemented as a moving selection of more or less two months around the target date.

Several pressure levels were assessed by means of various criteria for the analogy on the geopotential field \citep{Duband1970, Duband1974, Duband1981, Guilbaud1997}. It was found to be important to compute the analogy on multiple pressure levels and different temporal windows \citep{Guilbaud1998, Obled2002}. The Teweles\textendash Wobus (S1) criterion (Eq. \ref{eq:S1}), which allows for a comparison of the gradients, and thus an analogy of the atmospheric circulation, was identified as the most suited criteria by different studies \citep{Wilson1980, Woodcock1980, Guilbaud1998, Bontron2004}.

With a systematic assessment of the newly available NCEP/NCAR reanalysis data, \citet{Bontron2004} concluded that the coupled geopotential heights at 1000~hPa (Z1000) \& 12~h and 500~hPa (Z500) \& 24~h provided the best performance for the studied region (Table \ref{table:methods}). The analogy on the atmospheric circulation proposed by \citet{Bontron2004} is still, at the time of writing, often used operationally, and considered as a reference for benchmarking new parameterizations \citep[see e.g.][]{Horton2012, BenDaoud2015}. In order to assess the prediction, he introduced the Continuous Ranked Probability Score \citep[CRPS, Eq. \ref{eq:CRPS}, ][]{Brown1974}, which discards the issue of determining classes as with the Ranked Probability Score \citep{Epstein1969} previously in use.

Every variable of the NCEP/NCAR reanalysis was systematically assessed for each of the identified subregions of the study area (Sect. \ref{sec:case_study}). The present assessment considers every subregion separately and optimizes the spatial window and the number of analogs for every combination of variables, pressure levels, times of observation, and subregions (using the sequential calibration tool implemented in AtmoSwing, see Sect. \ref{sec:atmoswing-calibration}). Even though the best predictors may vary from one place to another due to different meteorological influences (see Fig. \ref{figure:variable_exploration_Chablais} for the 30 best predictors for the Chablais region, and Fig. \ref{figure:variable_exploration_SE_crests} for the Southeast ridges), 2 main conclusions can be drawn from the NCEP/NCAR reanalysis dataset for the area of interest, that meet those from \citet{Bontron2004}: (1) the variables describing the atmospheric circulation (pressure fields or geopotential heights) are the ones with the highest prediction capacity (the precipitation rate is even rarely selected in the 30 best predictors), and (2) these are better when compared by means of the S1 criteria (asterisk in Fig. \ref{figure:variable_exploration_Chablais} and \ref{figure:variable_exploration_SE_crests}) instead of the RMSE. The reason for this latter point is the better representation of the atmospheric circulation information when considering the shape of a pressure field rather than its values.

\citet{Horton2012} identified that the analogy on the atmospheric circulation as defined by \citet{Bontron2004} may not be comprehensive in an alpine environment, and that considering 4 atmospheric levels (1000, 850, 700, and 500~hPa at 12 or 24~h) instead of 2 could improve the performance (Table \ref{table:methods} -- the number of analogs $N_{1}$ was not provided globally, as it was calibrated for every subregion). An equivalent structure was also optimized by means of generic algorithms (PC-4Zgo), which is the topic of another paper \citep{Horton2016b}. As these new parametrizations provide performance gains for alpine catchments under varying meteorological influences, they are recommended for operational use.

A second level of analogy based on thermodynamic variables was then introduced by \citet{Mandon1985}, \citet{Vallee1986}, and \citet{Gibergans-Baguena2007}. After a systematic assessment, \citet{Bontron2004} pointed out that a moisture index (MI) made of the product of relative humidity at 850~hPa (RH850) and total precipitable water (TPW) gave the best performance (Table \ref{table:methods}). This index does not represent an actual physical quantity, but expresses the water content of the air column and its proximity to saturation.

\citet{Marty2010} tested other temporal windows for intraday application on the basis of a more comprehensive reanalysis dataset. He first proposed to change the hours of observation for both levels of analogy (both for 06~h and 18~h), and selected the 925~hPa level for the moisture analogy (Table \ref{table:methods}). The selected hours and atmospheric levels were not available before in the reanalysis dataset. Then, \citet{Marty2010} changed the moisture index into the moisture flux by adding the wind velocity (V700 or V925) component in the multiplication. He considered this flux at 700~hPa or 925~hPa (Table \ref{table:methods}).

\citet{Horton2012} also integrated an analogy on the moisture flux, after the circulation analogy on the 4 atmospheric levels (Table \ref{table:methods}). The number of analogs ($N_{1}$, $N_{2}$) were calibrated for every subregion. Similarly, an equivalent structure was optimized \citep[PC-4Zgo-2MIgo,][]{Horton2016b}. 

\citet{BenDaoud2010} applied the AM in the context of large floodplains (Sa\^{o}ne, Seine). He evaluated several variables usually used in weather prediction, amongst them the air temperature and the vertical velocity that presented a potential interest. The temperature (at the nearest grid point, on the 925~hPa \& 36~h and 600~hPa \& 12~h levels) could replace the rigid calendar preselection of $\pm$ 60 days around the target date by a more dynamic screening of similar situations in terms of air masses. The seasonal effect is indeed also present in the temperature data. The number of preselected dates is equivalent to the number of days one would have chosen with the calendar approach, and thus depends on the archive size: $N_{0} = 60 \cdot 2 \cdot n_{a}$ where $n_{a}$ is the number of years in the calibration period. \citet{BenDaoud2010} also reconsidered the parameters of the moisture index and ended up with both 925~hPa and 700~hPa levels, at 12~h and 24~h, or at every time step (6~h) between 06~h and 30~h (Table \ref{table:methods}).

Subsequently, \citet{BenDaoud2010} added an additional level of analogy, between the circulation and the moisture analogy (Table \ref{table:methods}), based on vertical velocity at 850~hPa (W850). This AM was developed for large floodplains in France, but was found to be not relevant for an Alpine environment where topography is mostly responsible for uplift of air masses \citep{Horton2012}. 

The optimal predictors vary from one region to another, along with the leading atmospheric processes. One will thus never get a unique parameterization of the AM valid for any place on earth, but the method needs to be adapted to the local conditions, available data, and to the size of the catchment of interest. Thus, there will always be local adaptations to be made for use in a new region.


\subsubsection{Discussion on the method}

A version of the AM was evaluated during the project STARDEX \citep[\textit{STAtistical and Regional dynamical Downscaling of EXtremes for European regions}, see][]{Goodess2003, Stardex2005}. One of the project goals was to compare various downscaling methods for the determination of weather extremes, and the AM was selected among the most interesting from various techniques \citep{Maheras2005, Schmidli2007}. Its use as adaptation method of climate models is also the subject of a growing number of studies \citep{Zorita1999, Wetterhall2005, Wetterhall2007, Matulla2007, Chardon2014, Dayon2015}. \citet{Bliefernicht2010} obtained better results witht the AM than downscaling methods based on weather typing.

\citet{Hamill2006} used an analogy based approach on the GFS reforecasts in order to correct systematic errors in the ensemble forecasts of temperature and precipitation. Indeed, the statistical approach pointed at some bias in estimates of the numerical model, which may have been adjusted by taking into account the intrinsic local climatology from the AM. Moreover, the under-dispersion of the ensemble forecast from the numerical model has been corrected using analogs \citep{Hamill2006}. Correction of ensemble forecast under-dispersion by means of the AM is also used operationally at EDF (\'{E}lectricit\'{e} de France).

\citet{Bliefernicht2010} observed that the performance of the AM is higher for winter than for summer. The relationship between synoptic predictors and local rainfall is lower in summer, due to convective precipitations that present a higher spatial variability and that depend on other parameters. Variables describing the synoptic circulation are indeed not able to predict the location of thunderstorm cells. This was also observed by \citet{BenDaoud2010}, who set up a specific model for the summer months (June 15 to September 15).

One of the AM limitations is the need for a substantial archive of the predictand variable, for example measured precipitations, that remain to be provided by the user. Without data on several decades, the AM is not applicable. Conversely, long predictor archives are also required, but this problem is now solved with reanalysis data, which may not be perfect in terms of homogeneity, but can be considered of sufficient quality. Moreover,  reanalysis data are available all around the world, which represent a great potential for the AM, and some are now extending to the whole 20$^{th}$ century. Another issue, still about data, concerns the operational forecasting: predictors describing forecasted target situations and the ones from the archive are not fully homogeneous, as they usually don't result from the same model and resolution. It is therefore necessary to use robust variables that depend from the numerical model characteristics at a minimum extent.

Another limitation is the fact that extreme events may be under-represented in the considered sample of analog dates. Indeed, in a limited weather archive, events with high return periods are not so numerous. Their number is certainly lower than the standard number of analogs considered, which can introduce a bias in the forecast. There are however techniques to correct this bias \citep[see][]{Marty2010}.

It is also legitimate to raise the question of the relevance of an approach based on archives of past situations in a context of climate change. The first potential issue is a possible change in atmospheric circulation. \citet{Philipp2007} observed certain trends in the synoptic atmospheric circulation over Europe, but with moderate frequencies. Moreover, the basic laws governing the atmosphere behavior will not be transformed \citep{Hewitson1996}. The assumption is that a large part of local climate change will result from changes in intensity, frequency and persistence of synoptic variables, but with other characteristics substantially similar to the present situation \citep{Hewitson1996}. Thus, if the archive of weather situations is long enough, it is reasonable to assume that a large part of future situations is already represented, even those whose frequency will change under different climatic conditions \citep{Wetterhall2005}. \citet{Dayon2015} has proven these assumptions to be accurate by showing the transferability in the future climate of the AM. They could demonstrate that the AM was able to predict the same trends in precipitations changes than Regional Climate Models. In addition, for operational use, climate change is relatively slow, and through continuous updating of the archive, the AM will incorporate new information progressively with no strong discontinuity. However, this may plea in favor of the approach proposed by \cite{BenDaoud2010} for defining the potential candidates to analogy: instead of considering a fixed period of two months before and after the target dates, one would prefer to select candidates that have approximately the same range of temperature.


\section{AtmoSwing}
\label{sec:atmoswing}

AtmoSwing is made of 3 main modules that are standalone, but do share a common code basis: the Forecaster, to process the operational forecasting, the Viewer, to display the forecast in a GIS environment, and the Optimizer, to calibrate/optimize the statistical relationship defining the analogy for a given predictand time series. Separating the Forecaster and the Viewer allows to automate the forecast on a server and to quickly display the results locally. The code is written in object oriented C++ and relies on the wxWidgets \citep{Smart2006} library to provide a cross-platform native experience to users. The software can thus be compiled on MS Windows, Linux / Unix, Mac (OS X, iOS), both in 32-bit and 64-bit.

The source code in under version control (with Mercurial), and is open source (on Bitbucket, www.atmoswing.org). Developments have been made with a test driven development (TDD) approach. A collection of more than 500 tests are frequently evaluated and completed during development, in order to verify that code changes do not introduce regression. Every analogy criterion, prediction score, searching and sorting functions, data manipulation, and so on, is tested. The integration tests specific to the AM rely on the results of another analog sorting software developed at the LTHE \textendash INPG university of Grenoble. They ensure that the results of AtmoSwing are exactly equivalent to their model, given the same parameters and data. These tests are part of the checks carried out regularly.

A user interface allows the creation of the precipitation database. Its generation consists in extracting the time series from text files in order to process them and save a database in the NetCDF format. During the process, Gumbel adjustments are automatically calculated in order to determine the values corresponding to different return periods. The time series are normalized by a selected return period (default 10~years) and their square root is eventually processed. The final database file contains both the raw and the normalized series, as well as characteristics of the gauging stations and some metadata.


\subsection{Modular approach and implementation}

An AtmoSwing great strength is that it is designed to process analogy downscaling in a modular fashion. The structure of the AM (number of analogy levels, number of predictors) is built dynamically (Fig. \ref{figure:flowchart_modules_atmoswing}), and nothing is fixed a priori. The software then performs successively as many analogy levels as the user specified, with all the predictors he wants. Each level of analogy processed results in an object containing target dates, analog dates, values of the analogy criteria, and other data. This object can be saved in a NetCDF file and/or can be injected into a new analogy level. The whole structure of the AM is defined in an XML file generated by the user. Even the time step of the method (6 or 24~hours for example) is a dynamic parameter.

Each implementation of the AM (see Sect. \ref{sec:method:references}) may enter this scheme, even if it consists of preprocessed variables (e.g. moisture index). Various preprocessing functions are implemented, as the calculation of the moisture index or flux, multiplication operations or calculation of the gradients. The user can specify the preprocessing method and the predictors to use, dynamically, in the XML file.


\subsection{Performance}

Although processing an analog forecast for a given target date is fast, when optimizing the AM, predictions are re-processed over long periods of several decades, which may become very time consuming. Thus, great effort has been made in order to reduce the processing time to a minimum. Waste of time were identified with profiling tools and cut down at different levels. The software also use the linear algebra library Eigen 3 \citep{Guennebaud2010} for calculations on vectors and matrices, which resulted in time saving. Multi-threading is also implemented so that the search for analog situations in the archive is distributed among the available threads.

The code optimization consited in reducing the most significant processing time identified by means of profiling tools. First, every identified redundancy in processing has been removed. Then, when looking for a certain date or data, the search looks first in the proximity where it is likely to be found instead of exploring an entire array. Similar data are not loaded twice, but shared pointers are used. Many other improvements allowed saving more time, for example the use of the quicksort method \citep{Hoare1962a} to sort the date vectors according to the values of analogy criteria. Different implementations were tested (many remain in the code as alternatives) in order to select the most efficient: for example, when storing analog dates according to their criteria value, it is faster to insert them in a fixed-size array rather than storing them all and sorting the array subsequently.

The major performance gains were obtained by:
\vspace*{-2mm}
\begin{itemize}
	\setlength\itemsep{-2px}
	\item reduction of the array sizes used in the calculations,
	\item use of pointers (and therefore the decrease of data copies),
	\item better search for dates in temporal vectors starting from the previous index (reduction of the range of the array to explore),
	\item better management of the analog vectors,
	\item preprocessed gradients on geopotential fields when using the S1 criteria,
	\item and finally the implementation of parallel calculations (multi-threading).
\end{itemize}


\subsection{AtmoSwing Forecaster}
\label{sec:forecaster}

The Forecaster module allows to process operational forecasts, defined by an XML file. A list of parameterizations is processed successively. The software can be compiled with a GUI (graphical user interface, Fig. \ref{figure:atmoswing-forecaster-gui}), or without in order to be used on a headless server through a command line interface. Processing a forecast requires very low computing capabilities and can be done on a low-end computer. 

The software first downloads the predictor describing the target situation, such as 1\degree\ GFS outputs \citep[Global Forecast System,][see Sect. \ref{sec:data}]{Kanamitsu1991,Kanamitsu1989}. It then interpolates linearly the gridded data to match the resolution of the archive (for example 2.5\degree\ in the case of the NCEP/NCAP reanalysis I). The analogs dates are next sought according to the selected parameterization, and the predictand data are associated with the corresponding dates. The results are finally saved in auto-describing NetCDF files. If required, a synthetic XML is generated for an easier integration on a web platform for example. Every step of the forecast, from the predictor downloading to the final results, is done in the software (and controlled through configuration), without use of external scripts (e.g. for data conversion).

When using a given parameterization of the AM, it has previously been optimized in a perfect prognosis context \citep[i.e. by optimizing on the reanalysis dataset; however, this does not take into account the uncertainty of the target situation when taken from operational forecasts of a Numerical Weather Prediction model,][]{Klein1963}. In operational forecasting, one should take into account the uncertainty of the predictor increasing with the lead time. A solution, presented in Sect. \ref{sec:optimization-operational}, consists in increasing the number of analog situations to keep with the lead time. This technique is available in AtmoSwing, as the number of analogs can be specified for every lead time, making such approach easily accessible.

The command-line interface allows to start the process for the present date, a selected past date, or the last $x$ days (as long as the predictors are available on the provider server). When there is nothing to process (no new predictor data available), the execution just stops, leading to no loss of computing resources. The recommended use is thus to set up a cron task on a Linux server in order to trigger the forecast every 30 minutes. When using GFS outputs, this would provide 4 forecasts a day with a reduced delay between GFS outputs availability and the analog forecast.


\subsection{AtmoSwing Viewer}
\label{sec:viewer}

The Viewer module allows displaying the resulting forecast files in an interactive GIS environment (Fig. \ref{figure:atmoswing-viewer-gui}). During the forecast, different parametrization variants of the same type of AM may be applied to a region; the reason being that some parameterizations may be specific for a subregion, when its meteorological influences differ, which is often the case even in relatively small catchments \citep{Horton2012}. The Viewer automatically gathers the similar AMs and provides a composite view of the optimal forecasts per subregion. The user can however choose to display a specific parameterization for the whole region, which is more consistent in terms of homogeneity of the analog dates.

The software provides several levels of synthesis of the forecasts. When it is opened, it automatically loads the most recent forecasts, eliminating the need to manually open files. It first offers a quick overview of possible alerts by means of color codes on the lead time switcher (upper right in the graphical user interface (GUI), see Fig. \ref{figure:atmoswing-viewer-gui}), which synthesizes the worst case scenario, or in the alarms panel (on the left part of the GUI). The alarms panel offers a synthesis of the higher forecasted values over the region, for the different AMs and the different lead times. By default, the colors are expressed relatively to 10~year return period values, for the $90^{th}$ percentile (can be changed in the preferences). This higher level of synthesis allows to quickly identify potential critical situations in the days ahead.

Then, the user can explore the forecasts more in details, starting from the map provided by the GUI (Fig. \ref{figure:atmoswing-viewer-gui}). The map display the forecast of the selected parameterization (upper left) and the selected lead time (upper right). The displayed AM is by default a composite of the parameterization variants for the region, but the user can choose a specific parameterization for the whole region by opening the tree view and selecting a child element. We also allowed a display of all lead times on a single map by means of a symbolic representation on a circular band with a box for every lead time (Fig. \ref{figure:atmoswing-viewer-snail}). The number of boxes is dynamically adjusted to the number of lead times. This representation offers a global spatiotemporal display for a chosen parameterization.

Color scales in the map are easily controlled by choosing the predictand ratio (raw value or ratio to different return periods) and the quantile of the distribution (on the left part of the GUI). Representation relatively to a return time better expresses the meaning of a certain precipitation amount for a given region, as climatology can be drastically different between two locations in a mountainous area, even if they are close to each other. All information relative to a rain gauge station (or catchments), such as its location, its name, or the values of different return periods, are stored in the forecast files, in order to be displayable for end users who do not have the predictand database.

By clicking on a station (forecast points) on the map (or by selection in a dropdown list on the left), a new window appears with a plot of the forecasted time series (Fig. \ref{figure:atmoswing-viewer-timeseries}). By default, the plot contains the usual 3 considered percentiles (90$^{th}$, 60$^{th}$, and 20$^{th}$), along with the 10 best analogs with a color code from yellow (tenth) to red (first). The 10 year return period is also displayed in order to put the forecast in perspective. The user can choose to hide any data or to display supplementary information (all analogs, all 10$^{th}$ percentiles, or all return periods) in the left panel. Traces of previous days forecasts are also automatically loaded and displayed in order to inform on the stability of the forecasts. 

The user can even go into further details and display the predictand cumulative distribution for a given lead time (Fig. \ref{figure:atmoswing-viewer-distribution}). This is useful when working on extreme precipitation, as comparing the distribution of all analogs versus the 10 best analogs provides information in order to interpret the forecast (trend to under/overestimation). Distribution of the analogy criteria (not shown) can also be displayed in order to identify eventual discontinuities in the criteria values.

Finally, one can see the details of the analog dates, along with the predictand and the criteria values in an interactive spreadsheet (not shown).

AtmoSwing Viewer relies on workspaces to specify the path to the forecast directories and the GIS layers. Many GIS formats are supported thanks to GDAL \cite[Geospatial Data Abstraction Library,][]{GDAL2014}. One can have as many layers as desired, and can control their display properties. It is thus easy to switch from a forecast for a region to another by opening a workspace file (XML format).


\subsubsection{Interpreting a precipitation forecast}
\label{sec:interpreting}

\citet{Djerboua2001} applied the AM developed by \citet{Guilbaud1997} in operational forecasting as part of the MAP project \citep[\textit{Mesoscale Alpine Programme}, see][]{Binder1996} during the special observation period \citep{Bougeault2001}. He noted that the 60$^{th}$ percentile was better to forecast precipitation amounts for common situations, but for strong to extreme events, the 90$^{th}$ percentile turned out to be a better indicator. It is therefore necessary to pay particular attention to the 90$^{th}$ percentile which, when reaching high values, may be indicative of a situation related to extreme precipitations, due the presence of several analog dates with significant observed precipitations amounts in the distribution \citep{Djerboua2001}. \citet{Bontron2004} made the same observation: he found the 60$^{th}$ percentile to be best for occurrence prediction, but the 90$^{th}$ percentile to be the most informative in order to forecast medium to high precipitation amounts ($P > P10/10$, one tenth of the 10~year return period value). In this regard, operators should pay particular attention to the distribution of the best analogs. If, for example, it is shifted to higher values, there is a risk of under-estimating the event when considering the middle of the full distribution. Obviously, if the target situation has its best analogs with high precipitations, then this situation is likely to be rare. So, when collecting a fixed number of analog situations, the worst ones are likely to be more common and will contribute to lower the resulting precipitation distribution, therefore a trend towards underestimation.


\citet{Marty2010} applied several validation scores to the quantiles of the AM distribution in operational forecasting. He concluded that the detection of the precipitation occurrence was better predicted by median quantiles (50\textendash 70~\%), with an optimum to 60~\%. However, once again, for significant rainfall, the 90$^{th}$ percentile gave the best performance. Comparing the results from the AM to an ensemble forecast, \citet{Marty2010} found the AM to be better than the considered ensembles, particularly for strong precipitation.

All AMs rely on atmospheric circulation information, while some add subsequent levels of analogy on moisture or other thermodynamic predictors (see Sect. \ref{sec:method:references}). However, these subsequent predictors were found to be relevant only on the first 3~days, and not much further, due to higher uncertainties in their forecast (see Sect. \ref{sec:optimization-operational}). This was found to be the case for moisture indexes and vertical velocity. The user has to keep this aspect in mind when interpreting forecasts over a range of lead times.


\subsection{AtmoSwing Downscaler}
\label{sec:downscaler}




\subsection{AtmoSwing Optimizer}
\label{sec:optimizer}

AtmoSwing Optimizer is a single tool that integrates different optimization methods, presented in Sect. \ref{sec:atmoswing-calibration} to \ref{sec:atmoswing-optimization}. Optimization is essentially performed in the calibration framework (Sect. \ref{sec:calibration-framework}), where one tries to maximize (by means of performance scores, see Sect. \ref{sec:forecasts-scores}) the information that can be extracted from the available predictors and predictand archives.

However, in operational use, a further ingredient arises : the model from which the target synoptic situations are taken for the coming days, and the increasing uncertainty related to the lead time. Depending on the properties of these forecasts, the operational scheme has to be tuned (Sect. \ref{sec:optimization-operational}).


\subsubsection{Calibration framework}
\label{sec:calibration-framework}

The calibration of the AM is usually carried out in a perfect prognosis \citep{Klein1959} framework \citep{Bontron2004, BenDaoud2010}. Perfect prognosis uses observed or reanalyzed data to calibrate the relationship between predictors and predictands. As a result, this framework will identify and provide us with relationships that are as close as possible to the natural links between predictors and predictands. However, no model is perfect, and even reanalysis data may contain bias that cannot be ignored. The calibration process has to try to cope with such bias, but also with the data spatial resolution, that may be too rough for certain variables like humidity or vertical velocity. For these reasons, the statistical relationships identified in the perfect prognosis framework should hopefully be applied to new target situations (e.g. resulting from an operational NWP model) with characteristics as similar as possible to the those of the reanalyses.

Another reason for working in a perfect prognosis framework is that numerical models evolve continuously, and so does the prediction they provide. Considering reforecasts would allow us to work on a homogeneous dataset, as they are regularly reprocessed with a defined version of the model. However, one would need to redo the calibration procedure every time a new version is available, in order to reduce the bias \citep{Wilson2002}. Moreover, the length of reanalyses datasets are usually much longer than reforecast datasets, which allows us to identify more robust relationships. The size of the archive is indeed an important criteria for the AM.

The statistical relationship is established on a calibration period that is as long as possible. For every day of this period, a search for analogs is performed, the predictand data are associated with the corresponding dates and a prediction score is calculated. During the search for analogs situations, 120 days around the target date are excluded (thus excluding data in the same year) in order to consider only truly independent candidates days.

A validation period is always considered. It consists of an independent period that is never used as target neither candidate. Validating the parameters of the AM is very important in order to avoid over-parametrization and thus to ensure that the statistical relationship is valid on another period. In order to account for climate change and the evolution of the measuring techniques, it is recommended to use a noncontinuous period for validating, distributed over the whole archive \citep{BenDaoud2010}. The user can thus specify a list of the years to keep for the validation and AtmoSwing Optimizer handles this aspect easily by both removing the validation years from possible candidate situations, and by automatically processing the validation score on these years at the end of the optimization.


\subsubsection{Implemented prediction scores}
\label{sec:forecasts-scores}

Most often, the accuracy of the parameters for precipitations downscaling is evaluated by means of the CRPS \citep[Continuous Ranked Probability Score,][]{Brown1974, Matheson1976, Hersbach2000}. It is the only score that will be detailed hereafter (in Sect. \ref{sec:prob_forecasts}). In addition, other scores are implemented in AtmoSwing Optimizer. The following sections list the scores presently available, but will not detail them.


\textbf{Discrete deterministic predictions}

Deterministic predictions consider no uncertainty. A single value is provided for a variable. The first group of this type of prediction is based on discrete values, also called categories. These scores are used, for example, to evaluate a deterministic prediction of threshold exceedance. In our case, the continuous probabilistic nature of an analogy prediction can be transformed into a discrete prediction by considering a threshold exceedance and a fixed percentile from the distribution. These scores rely on a contingency table, which is here a table containing the sums of observed / unobserved and predicted / unpredicted events \citep{Wilks2006}. On the basis of this table, multiple scores can be processed within AtmoSwing:

\begin{itemize}
	\setlength\itemsep{-1mm}
	\item Proportion correct \citep{Finley1884}
	\item Threat Score \citep{Gilbert1884}
	\item Bias
	\item False Alarm Ratio
	\item Hit Rate or Probabiliy of Detection
	\item False Alarm Rate
	\item Heidke Skill Score \citep{Heidke1926}
	\item Peirce Skill Score \citep{Peirce1884}
	\item Gilbert Skill Score or Equitable Threat Score \citep{Gilbert1884}
\end{itemize}


\textbf{Continuous deterministic predictions}

The difference of the continuous deterministic predictions compared to discrete ones is that they provide non-discrete values that must be evaluated with distance measures. In our application, the distribution of the analogs is summarized by a chosen percentile. Available scores are the following:

\begin{itemize}
	\setlength\itemsep{-1mm}
	\item Mean Absolute Error
	\item Root Mean Squared Error
\end{itemize}


\textbf{Discrete probabilistic predictions}

In the case of discrete probabilistic predictions, one works with probabilities of occurrence or probability of belonging to a certain category. The implemented options are:

\begin{itemize}
	\setlength\itemsep{-1mm}
	\item Brier Score \citep{Brier1950}
	\item ROC diagramm \citep[Relative Operating Characteristic or Receiver Operating Characteristic,][]{Mason1982}
	\item RPS \citep[Ranked Probability Score,][]{Epstein1969}
	\item SEEPS \citep[Stable Equitable Error in Probability Space,][]{Rodwell2010,Rodwell2011}
\end{itemize}


\textbf{Continuous probabilistic predictions}
\label{sec:prob_forecasts}

Continuous probabilistic predictions of a variable are issued in the form of the expected statistical distribution for this variable. They are expressed either in terms of distribution or by probability density, which needs to be compared to an observed value. This is the situation one meets when downscaling precipitations with the AM.

Most applications mainly rely on the CRPS \citep[Continuous Ranked Probability Score,][]{Brown1974, Matheson1976, Hersbach2000}. It allows assessing the predicted cumulative distribution functions $F(y)$, for example of the precipitation values $y$ from analog situations, compared to the observed value $y^{0}$. The better the prediction, the smaller the score. The mean CRPS of a prediction series of length $n$ can be written:

\begin{equation}
\label{eq:CRPS}
CRPS = \frac{1}{n} \sum_{i=1}^{n} \left(  \int_{-\infty}^{+\infty} \left[ F_{i}(y)-H_{i}(y-y_{i}^{0})\right]^{2} dy \right) 
\end{equation}
where $H(y-y_{i}^{0})$ is the Heaviside function that is null when $y-y_{i}^{0}<0$, and has the value 1 otherwise. The mean CRPS is averaged on the calibration, respectively the validation periods, on all days, may they be dry, slightly rainy or with heavy precipitation.

This score is now commonly used for the evaluation of continuous variables prediction systems \citep{Casati2008, Marty2010}. To compare the value of the score in regard to a reference, one often considers its skill score value, and use the climatological distribution as the reference. The CRPSS (\textit{Continuous Ranked Probability Skill Score}) is thus defined as following:

\begin{equation}
\label{eq:CRPSS}
CRPSS = \frac{CRPS-CRPS_{r}}{CRPS_{p}-CRPS_{r}} = 1-\frac{CRPS}{CRPS_{r}}
\end{equation}
where $CRPS_{r}$ is the CRPS value for the reference and $CRPS_{p}$ would be the one for a perfect prediction (which implies $CRPS_{p}~=~0$).

The CRPS can be decomposed into several indicators, also implemented into AtmoSwing Optimizer, such as:

\begin{itemize}
	\setlength\itemsep{-1mm}
	\item Reliability \citep{Hersbach2000}
	\item Resolution / uncertainty \citep{Hersbach2000}
	\item Sharpness \citep{Bontron2004}
	\item Accuracy \citep{Bontron2004}
\end{itemize}

Finally, the rank diagram \citep{Talagrand1997} and its accuracy as defined by \citet{Candille2005} are also available.


\subsubsection{The sequential calibration}
\label{sec:atmoswing-calibration}

The calibration procedure that we call ''sequential'' or ''classic'', but which is also named ''optimization'' \cite[eg. by ][]{BenDaoud2015}, was developed at LTHE \textendash INPG university of Grenoble \citep{Bontron2004}. It is a semi-automatic procedure that determines the optimal parameters for the different variables of each level of analogy. The analogy levels (eg. the atmospheric circulation or moisture index) are calibrated sequentially. The procedure consists of the following steps \citep{Bontron2004}:

\begin{enumerate}
	\item Manual selection of the following parameters:
	\begin{enumerate}
		\item meteorological variable (e.g. geopotential, temperature, relative humidity, etc.),
		\item pressure level (e.g. 700 hPa, ...),
		\item temporal window (hour of observation \textendash e.g. 6, or 12~h~UTC),
		\item initial analog numbers (e.g. $N_{1}=50$).
	\end{enumerate}
	
	\item For every level of analogy:
	\begin{enumerate}
		\item Identification of the most skilled unitary cell (1~point for moisture variables and 4 for the geopotential height when using the S1 criteria) over a large domain. Every point (or cell) of the full domain is assessed jointly on all predictors of the level of analogy (consisting generally of the same variable, but on different pressure levels and at different hours).
		\item From this most skilled point, the spatial window is expanded by successive iterations in the direction of greater performance gain. The detailed stages are the followings: (i) The unitary spatial window is expanded in every 4 directions successively. The performance score is processed for these 4 windows. (ii) Only the direction providing the best improvement is applied to the spatial window. (iii) From this new spatial window, an increase in every 4 directions is once again assessed, and the best improvement is applied. (iv) The spatial window grows up by repeating the previous steps, until no improvement is reached.
		\item The number of analog situations is then reconsidered and optimized for the current level of analogy.
		\item A new level of analogy can then be added, based on other variables (such as the moisture index) on predefined pressure levels and time frames. The number of analogs for the next level of analogy is initiated at a chosen value. Then, the procedure starts again from step (a) for the new level. The parameters calibrated on the previous analog levels are fixed and do not change (except the numbers of analogs of all levels of analogy, that are optimized once again at the final stage). 
	\end{enumerate}
	\item Finally, the numbers of analogs are re-assessed for the different levels of analogy. This is done iteratively by varying the number of analogs of each level in a systematic way.
\end{enumerate}

The calibration is thus done in successive steps, on a limited number of parameters. Previously calibrated parameters are generally not reassessed. The advantage of this method is that it is relatively fast, it provides acceptable results, and it has low computing requirements. 

Small improvements were added to this method, then named ''classic+'', by allowing the spatial windows to do other moves, such as: (1) increase in 2 simultaneous directions, (2) decrease in 1 or 2 simultaneous directions, (3) expansion or contraction (in every direction), (4) shift of the window (without resizing) in 8 directions (including diagonals), and finally (5) all the moves described above, but with a factor of 2, 3, or more. For example, an increase by 2 units in one (or more) direction is assessed. This allows to skip one size that may not be optimal. These supplementary steps often result in spatial windows that are a bit different, but the performance gain is rather marginal.

\subsubsection{Monte\textendash Carlo analysis}

A Monte\textendash Carlo analysis is also implemented in AtmoSwing. It performs thousands assessments of random parameters within given ranges. This method is not efficient to find the best parameters set, but helps to better understand the sensitivity of the parameters.

For example, a Monte\textendash Carlo analysis was performed on the PC-2Z (Table \ref{table:methods}) AM for the southeastern crests on the upper Rh\^{o}ne catchment in Switzerland, with 10,000 random selections of its parameters according to a uniform law (the analysis was also performed in other subregions of the upper Rh\^{o}ne catchment in Switzerland, but the conclusions depicted here are similar). Unlike conventional calibration, the spatial windows on Z500 and Z1000 were not necessarily overlapping. Thus, 9 parameters were varying together (8 for the spatial windows and 1 for the number of analogs)

Figure \ref{figure:monte_carlo_r1} presents the resulting scatter of random exploration of the parameters space, along with the results of the sequential calibration (red cross). Results are illustrated here for the 4 parameters defining the spatial window on Z500. Despite the high number of simulations, the upper portion of the distributions seems incomplete, and the score of the sequential calibration is not matched. Although the method is poor to find efficiently the best parameters, it is informative as to the shape of the scatter plots.

The shape of the scatter plots from Fig. \ref{figure:monte_carlo_r1} reveals a low sensitivity as to the exact location of the spatial windows. There is a maximum threshold for minimum longitudes and latitudes and, inversely, a minimum threshold for maximum latitudes and longitudes, but outside of these limits, the distribution slope is more gentle. A spatial window can thus be a bit larger than its optimal size without a significant drop in performance, as long as it includes at least one critical region. This was also observed by \citet{Bontron2004}, who noted that ''\textit{performance slowly decreases if we consider a slightly too large window, while the use of too small windows results in strong performance loss}''. The dilution of a part of the relevant synoptic information has therefore not necessarily a significant negative impact on performance, while ignoring some of this information leads to undesirable loss of performance. It is the same for the analogs number (not shown), for which, past an optimum, the upper slope of the distribution decreases slowly.

The same analysis has been conducted on the AM with 2 levels of analogy, PC-2Z-2MI (Table \ref{table:methods}), and the results on the number of analogs on the first and the second level are illustrated in Fig. \ref{figure:monte_carlo_r2}. One can see that the AM is not very sensitive to the number of analogs on the first level of analogy, when considering a second level afterwards, as long as this number is not too small. The trend on the second level is more apparent, but a large tolerance seems possible.

The use of such a random method allows informing on the parameters sensitivity, and so on the importance of the expected precision of the calibration results. It helps understanding how different parameterizations can end up to relatively similar performances. Using Monte Carlo analyses allows to easily display the AM parameters sensitivity. 


\subsubsection{Global optimization}
\label{sec:atmoswing-optimization}

Due to limitations in the sequential approach, we decided to explore optimization techniques that could handle all parameters fully automatically. The \citet{Nelder1965a} method was first assessed, but was found unsuitable for this purpose. Because of the complexity of the AM and its non-linearity, a technique of global optimization is required. Genetic algorithms were thus implemented in AtmoSwing Optimizer in order to perform a global optimization of the AM. This allows for a fully automatic and objective optimization of the AM. However, as this topic is rather consequent, it is the subject of other coming publications \cite[see][]{Horton2016a, Horton2016b}.


\subsubsection{Optimization for operational use}
\label{sec:optimization-operational}

Up to now, the AM has been optimized essentially by replaying past situations that were taken from a unique meteorological archive. Therefore, the synoptic variables have similar properties in terms of resolution, models that have processed them, etc... However, when it comes to operational forecasting, as already mentioned, the resulting AM will be applied to target situations that are no longer similar to the reanalyzed ones. They will be taken from global model forecasts, which may not be those used to elaborate the archive of reanalyzed situations. Thus, these new targets will display characteristics different from those of the archive, and will in particular contain larger uncertainties, especially at growing lead-times.

Eventually, a meteorological variable that was proven to be a good predictor during the calibration of the AM may be poorly predicted by the forecast NWP model selected beyond a certain lead time. In this regards, it should be dropped after the lead time in question (see Sect. \ref{sec:interpreting}).

To assess and address these operational aspects, the best option is to collect a dataset of reforecast from the specific NWP model selected. Then, distinct variants of AM parameterizations can be assessed on different lead times. For example, when using moisture variables for the second level of analogy, \citet{Thevenot2004} showed that beyond a lead time of 3 days, the AM with two levels did not do better that the one with a unique level of analogy. It comes from the fact that large scale geopotential variables are correctly predicted up to 8 or 10 days, while humidity variables are not, at least by the current version of the model considered.

Next, we assume that for the synoptic variables used as predictors, the model predictions have more uncertainties than the reanalyses, but no systematic bias. To optimize further the AM, it can be considered that the further the lead time, the more uncertain the synoptic forecasts and therefore the more uncertain the precipitation forecasts could be. This can been addressed by reconsidering, for each lead-time, the optimal number of analogs to select, for reforecast data from a particular NWP model \citep{Thevenot2004}. The underlying idea is that if the model proves perfect, then the number of analogs should remain close to that obtained in the perfect progonosis framework. While if the forecast becomes irrelevant, for example at distant lead times, the AM should propose a prediction closer and closer to the climatological distribution of the predictand. The optimal number of analog situations will thus increase with the lead time, and should be optimized for every lead time on the reforecast dataset \citep[see][for the details]{Thevenot2004}. This option is implemented in AtmoSwing Forecaster (see Sect. \ref{sec:forecaster}).

It should be stressed that these operational aspects are dependent on the model used to provide the AM with synoptic forecasts, and on the availability of a reforecast data to perform the tuning of the AM to this particular model.


\section{Conclusions and perspectives}
\label{sec:conclusions}

Processing operational forecasts by means of AtmoSwing requests in the end very low computing infrastructure and can provide useful information, such as early warning for extreme precipitation, in the case of an application in flood forecasting. The Forecaster is very flexible as it builds the desired method in a dynamic way, and can thus implement multiple variants of the AM. The connection with open access NWP model such as GFS is easy and very efficient (data are collected quickly after being available, and processed in a few minutes). The Viewer offers a user-friendly display of the forecasts, with different levels of synthesis and details. The Optimizer implements different optimization techniques, such as the sequential approach, a Monte\textendash Carlo method, and a global optimization technique. Obviously, it is used only occasionally for a given location: for a first implementation of an AM, in case of a change in the archive, or of a substantial updating, etc.

Meanwhile, several additions would be nice to have in AtmoSwing for operational forecasting. The first one would be using outputs from multiple global NWP models within one forecast, namely making multi-models forecasts, in order to take into account the variability between various providers. In the same direction, \citet{Thevenot2004} showed the benefit of using ensembles of global NWP forecasts as input for the method (in his case the 51 traces from the EFS of ECMWF). This approach takes into account the uncertainties on predictors from the global model. Its implementation is a combination of the selected analog days associated with each of the traces. Rainfall distribution is then established on all analogs. The forecast on the ensemble was found to be more accurate than the deterministic control for a lead time of 4 days and more \citep{Thevenot2004}. 

Next, a bias correction should be implemented. \citet{Marty2010} has indeed observed that the frequency of the forecasted days without precipitation was biased and underestimated the actual frequency of zero precipitation. On the contrary, the frequency of the forecasted days with precipitation overestimated the observed frequencies. On this basis, \citet{Marty2010} proposed a bias correction technique, that should be implemented as well. This issue occurs in operational forecasting and was not observed in perfect prognosis.

As it was shown in the historical section, the AM evolves, with the availability of new data, computer facilities and progress in NWP models, and still proves to bring complementary information on predictands like precipitation, for example at long lead time. Its interest in climatological downscaling has not been addressed in this paper but should be mentioned. However, there remain still many possibilities to be explored. Amongst them, one can mention:

\begin{itemize}
	\item an optimization per season in order to get parameterizations specific to the leading processes during the period in question;
	\item optimizations specific for extreme events, with an objective function tailored to the determination of the most critical situations;
	\item a better insight in the role of the length of the archive, by using long reanalyses over the $20^{th}$ century;	
	\item a weighting of the predictor grids \citep[see][]{Bliefernicht2010};
	\item assessment of potential indicators based on the properties of the distribution of all analogs or the 10 best, for example;
	\item assessment of the relevance of an automatic interpretation of the distribution in order to provide the most likely expected value;
\end{itemize}


\section*{Code availability}

AtmoSwing is open source, under the CDDL license. It is developed under the Git distributed revision control, and the source code can be found at:

\begin{itemize}
	\item http://www.atmoswing.org
	\item https://github.com/atmoswing/atmoswing/
\end{itemize}


\section*{Acknowledgements}
Thanks to Lucien Schreiber and Richard Metzger for their programming advices and to Renaud Marty for his active involvement in testing AtmoSwing against his code base.



\bibliography{references}

\clearpage


\begin{figure}[t]
	\includegraphics[width=7.5cm]{figures/variable_exploration_Chablais.pdf}
	\caption{Performance score (CRPSS) of the 30 best variables from the NCEP/NCAR reanalysis dataset, when considered separately (no combination), for the Chablais region (Sect. \ref{sec:case_study}). The analogy criteria is S1 when there is an asterisk next to the variable name, and RMSE otherwise. Color illustrates the variable type: green = atmospheric circulation, blue = moisture, orange = temperature, yellow = radiation, purple = vertical velocity, and gray = other. SLP stands for sea level pressure, and Z for geopotential height}
	\label{figure:variable_exploration_Chablais}
\end{figure}

\begin{figure}[t]
	\includegraphics[width=7.5cm]{figures/variable_exploration_SE_crests.pdf}
	\caption{Same as Fig. \ref{figure:variable_exploration_SE_crests}, but for the southeast ridges.}
	\label{figure:variable_exploration_SE_crests}
\end{figure}

\begin{figure}[t]
	\includegraphics[width=8.3cm]{figures/fig01.pdf}
	\caption{Proposed structure for naming the parameterizations of the AM.}
	\label{figure:nomenclature}
\end{figure}

\begin{figure}[t]
	\includegraphics[width=8.3cm]{figures/fig05.pdf}
	\caption{Simplified organizational chart of the AM implementation in AtmoSwing.}
	\label{figure:flowchart_modules_atmoswing}
\end{figure}

\begin{figure}[t]
	\includegraphics[width=8.3cm]{figures/fig06.png}
	\caption{Graphical user interface of the Forecaster module. A list of different parameterizations is being processed.}
	\label{figure:atmoswing-forecaster-gui}
\end{figure}

\begin{figure*}[t]
	\includegraphics[width=18cm]{figures/fig07.png}
	\caption{Graphical user interface of the Viewer module (Elevation data from The Shuttle Radar Topography Mission (SRTM), and hydrological network from SwissTopo).}
	\label{figure:atmoswing-viewer-gui}
\end{figure*}

\begin{figure}[t]
	\includegraphics[width=8.3cm]{figures/fig08.png}
	\caption{Visualization of multiple lead times on the map (Elevation data from the SRTM, and hydrological network from SwissTopo).}
	\label{figure:atmoswing-viewer-snail}
\end{figure}

\begin{figure}[t]
	\includegraphics[width=8.3cm]{figures/fig09.png}
	\caption{Visualization of the forecasted time series.}
	\label{figure:atmoswing-viewer-timeseries}
\end{figure}

\begin{figure}[t]
	\includegraphics[width=8.3cm]{figures/fig10.png}
	\caption{Visualization of the forecasted precipitation distribution for a given lead time.}
	\label{figure:atmoswing-viewer-distribution}
\end{figure}

\begin{figure}[t]
	\includegraphics[width=8.3cm]{figures/fig11.png}
	\caption{Example of a Monte\textendash Carlo analysis on the PC-2Z (Table \ref{table:methods}) AM. Results are illustrated for the 4 parameters defining the spatial window on Z500, along with the results of the sequential calibration (red cross).}
	\label{figure:monte_carlo_r1}
\end{figure}

\begin{figure}[t]
	\includegraphics[width=8.3cm]{figures/fig12.png}
	\caption{Example of a Monte\textendash Carlo analysis on the PC-2Z-2MI (Table \ref{table:methods}) AM. Results are illustrated for the number of analogs on the first and second level of analogy, along with the results of the sequential calibration (red cross).}
	\label{figure:monte_carlo_r2}
\end{figure}

\clearpage



\begin{table*}[t]
	\caption{Reanalysis datasets that can be read by AtmoSwing.}
	\begin{center}
		\begin{tabular}{ccccccc}
			\hline
			\multirow{2}{*}{\textbf{Name}} & \multirow{2}{*}{\textbf{Institution}} & \textbf{Period} & \textbf{Output} & \textbf{Model} & \textbf{Model} & \textbf{Type of}\\ 
			&& \textbf{of record} & \textbf{resolution} & \textbf{resolution} & \textbf{vintage} & \textbf{input} \\ 
			\hline 
			\textbf{NR-1} & NCEP, NCAR & 1948 -- present & 2.5\degree x 2.5\degree & T62 ($\sim$1.88\degree), L28 & 1995 & full \\
			\textbf{NR-2} & NCEP, DOE & 1979 -- present & 2.5\degree x 2.5\degree & T62 ($\sim$1.88\degree), L28 & 2001 & full \\
			\textbf{ERA-INT} & ECMWF & 1979 -- present & 0.75\degree x 0.75\degree & TL255 ($\sim$0.70\degree), L60 & 2006 & full \\
			\textbf{20CR-2c} & NOAA-CIRES & 1851 -- 2014 & 2\degree x 2\degree & T62 ($\sim$1.88\degree), L28 & 2008 & surface \\
			\textbf{CFSR} & NCEP & 1979 -- present & 0.5\degree x 0.5\degree & T382 ($\sim$0.31\degree), L64 & 2009 & full \\
			\textbf{JRA-55}  & JMA & 1958 -- present & 1.25\degree x 1.25\degree & TL319 ($\sim$0.36\degree), L60 & 2009 & full \\
			\textbf{JRA-55C}  & JMA & 1958 -- 2015 & 1.25\degree x 1.25\degree & TL319 ($\sim$0.36\degree), L60 & 2009 & conventional \\
			\textbf{ERA-20C} & ECMWF & 1900 -- 2010 & 1\degree x 1\degree & TL159 ($\sim$1.13\degree), L91 & 2012 & surface \\
			\textbf{MERRA-2} & NASA GMAO & 1980 -- present & 0.625\degree x 0.5\degree & 0.625\degree x 0.5\degree, L72 & 2014 & full \\ 
			\textbf{CERA-20C} & ECMWF & 1901 -- 2010 & 1\degree x 1\degree & T159 ($\sim$1.13\degree), L91 & 2016 & surface \\
			\hline 
		\end{tabular} 
	\end{center}
	\label{table:datasets}
\end{table*}

\begin{table*}[t]
	\caption{Some existing analogue methods, listed by increasing complexity. P0 is the preselection (PC: on calendar basis, that is $\pm 60$ days around the target date), L1, L2 and L3 are the subsequent levels of analogy. N1, N2 and N3 are the number of analogues to select at each level of analogy. The meteorological variables are: Z -- geopotential height, T -- air temperature, W -- vertical velocity, MI -- moisture index, which is the product of the relative humidity at the given pressure level and the total water column, MF -- moisture flux, which is the product of MI with the wind intensity. The analogy criterion is S1 for Z and RMSE for the other variables.}
	\footnotesize
	\begin{center}
		\begin{tabular}{ccccccccl}
			\hline
			\textbf{Type} & \textbf{P0} & \textbf{L1} & \textbf{N1} & \textbf{L2} & \textbf{N2} & \textbf{L3} & \textbf{N3} & \textbf{Reference} \\ 
			\hline 
			\textbf{PC-2Z} & PC & Z1000@12h & 50 &&&&& \citealt{Bontron2004} \\
			&& Z500@24h &&&&&& \\
			\hline 
			\textbf{PC-4Z} & PC & Z1000@06h & {\raise.17ex\hbox{$\scriptstyle\sim$}}27 &&&&& \citealt{Horton2018a} \\
			&& Z1000@30h &&&&&& \\
			&& Z700@24h &&&&&& \\
			&& Z500@12h &&&&&& \\
			\hline 
			\textbf{PC-2Z-2MI} & PC & Z1000@12h & 70 & MI850@12h & 30 &&& \citealt{Bontron2004} \\
			&& Z500@24h && MI850@24h &&&& \\
			\hline 
			\textbf{PC-2Z-2MI} & PC & Z1000@06h & 75 & MI925@06h & 30 &&& \citealt{Marty2010} \\
			&& Z500@18h && MI925@18h &&&& \\
			\hline 
			\textbf{PC-2Z-2MF} & PC & Z1000@06h & 60 & MF700@06h$^{\dagger}$ & 25 &&& \citealt{Marty2010} \\
			&& Z500@18h && MF700@18h &&&& \\
			\hline 
			\textbf{PC-4Z-2MI} & PC & Z1000@30h & {\raise.17ex\hbox{$\scriptstyle\sim$}}63 & MI700@24h & {\raise.17ex\hbox{$\scriptstyle\sim$}}24 &&& \citealt{Horton2018a}\\
			&& Z850@12h && MI600@12h &&&& \\
			&& Z700@24h &&&&&& \\
			&& Z400@12h &&&&&& \\
			\hline 
			\textbf{PT-2Z-4MI} & T925@36h & Z1000@12h & 70 & MI925@12h & 25 &&& \citealt{BenDaoud2016} \\
			& T600@12h & Z500@24h && MI925@24h &&&& \\
			&&&& MI700@12h &&&& \\
			&&&& MI700@24h &&&& \\
			\hline 
			\textbf{PT-2Z-10MI} & T925@36h & Z1000@12h & 70 & MI925@06-30h & 25 &&& \citealt{BenDaoud2010} \\
			& T600@12h & Z500@24h && MI700@06-30h &&&& \\
			\hline 
			\textbf{PT-2Z-4W-4MI} & T925@36h & Z1000@12h & 170 & W850@06h & 70 & MI925@12h & 25 & \citealt{BenDaoud2016} \\
			& T600@12h & Z500@24h && W850@12h && MI925@24h && \\
			&&&& W850@18h && MI700@12h && \\
			&&&& W850@24h && MI700@24h && \\
			\hline 
		\end{tabular} 
	\end{center}

	$\dagger$ or MF925@06h+18h as an alternative
	\label{table:methods}
\end{table*}


\end{document}